{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e731deb-633c-4764-bc81-2073e3f4fe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import json\n",
    "import requests\n",
    "\n",
    "import wrangle\n",
    "import prepare as prep\n",
    "\n",
    "from env import github_token, github_username\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import re\n",
    "import unicodedata\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9e8c84-8a02-425d-8ec1-1ef78dee1432",
   "metadata": {},
   "source": [
    "## Acquire and Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "330ef287-6f8d-4fc8-8ec9-60412aa73585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mcastrolab/Brazil-Covid19-e0-change</td>\n",
       "      <td>R</td>\n",
       "      <td># Reduction in life expectancy in Brazil after...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jschoeley/de0anim</td>\n",
       "      <td>R</td>\n",
       "      <td># Animated annual changes in life-expectancy\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sychi77/Thoracic_Surgery_Patient_Survival</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td># Thoracic Surgery for Lung Cancer Data Set\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ashtad63/HackerRank-Data-Scientist-Hiring-Test</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td># HackerRank Data Scientist Hiring Test: Predi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OxfordDemSci/ex2020</td>\n",
       "      <td>R</td>\n",
       "      <td>&lt;p align=\"center\"&gt;\\n  &lt;img src=\"https://github...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             repo          language  \\\n",
       "0             mcastrolab/Brazil-Covid19-e0-change                 R   \n",
       "1                               jschoeley/de0anim                 R   \n",
       "2       sychi77/Thoracic_Surgery_Patient_Survival  Jupyter Notebook   \n",
       "3  ashtad63/HackerRank-Data-Scientist-Hiring-Test  Jupyter Notebook   \n",
       "4                             OxfordDemSci/ex2020                 R   \n",
       "\n",
       "                                     readme_contents  \n",
       "0  # Reduction in life expectancy in Brazil after...  \n",
       "1  # Animated annual changes in life-expectancy\\n...  \n",
       "2  # Thoracic Surgery for Lung Cancer Data Set\\n ...  \n",
       "3  # HackerRank Data Scientist Hiring Test: Predi...  \n",
       "4  <p align=\"center\">\\n  <img src=\"https://github...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(\"data.json\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f3e87ad-ea4f-4b54-811f-cadfd00bb84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 166 entries, 0 to 165\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   repo             166 non-null    object\n",
      " 1   language         157 non-null    object\n",
      " 2   readme_contents  166 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 4.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87be79c2-1cc8-4b08-a996-5373a22b9cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ef1f98-2f2f-4391-a169-c4aec018221c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prep.prep_data(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8682955f-8528-41cc-a976-0743630b78bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0650140b-4728-4d59-936b-29974d3a50bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_languages = prep.prep_data(df_copy, keep_top_languages=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6797f35-b1be-4e8a-95f1-ea88fd2980a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_languages.language.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1947a26b-cba3-49b9-bc1a-7ea599b26a93",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060f69ec-99a8-4641-8938-e0b9fb95abaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "    train_validate, test = train_test_split(df, test_size=.2, random_state=123)\n",
    "    train, validate = train_test_split(train_validate, test_size=.3, random_state=123)\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe419d65-1be5-4535-a377-d1728a687adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = split_data(df)\n",
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bf3a43-8e70-4903-b534-7b5a98106e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_languages, validate_languages, test_languages = split_data(df_all_languages)\n",
    "train_languages.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba486b6-49a4-4e43-92cc-385fbf47a696",
   "metadata": {},
   "source": [
    "## Explore \n",
    "#### Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1998897c-932a-4448-b7b8-b8f29c0ee40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_counts_and_ratios(df, column):\n",
    "    \"\"\"\n",
    "    Takes in a dataframe and a string of a single column\n",
    "    Returns a dataframe with absolute value counts and percentage value counts\n",
    "    \"\"\"\n",
    "    labels = pd.concat([df[column].value_counts(),\n",
    "                    df[column].value_counts(normalize=True)], axis=1)\n",
    "    labels.columns = ['n', 'percent']\n",
    "    labels\n",
    "    return labels\n",
    "\n",
    "show_counts_and_ratios(train, \"language\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df16c7c3-6b2d-42cb-8c84-aa41fa7baf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    'A simple function to cleanup text data'\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    text = (unicodedata.normalize('NFKD', text)\n",
    "             .encode('ascii', 'ignore')\n",
    "             .decode('utf-8', 'ignore')\n",
    "             .lower())\n",
    "    words = re.sub(r'[^\\w\\s]', '', text).split()\n",
    "    return [wnl.lemmatize(word) for word in words if word not in stopwords]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6b2ece-ad8d-4f8b-8ef7-a845c0b5acba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create lists of words for each language category\n",
    "other = clean(' '.join(train[train.language == 'other'].original))\n",
    "python = clean(' '.join(train[train.language == 'Python'].original))\n",
    "r = clean(' '.join(train[train.language == 'R'].original))\n",
    "html = clean(' '.join(train[train.language == 'HTML'].original))\n",
    "all_words = clean(' '.join(train.original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a1195b-d41c-44ad-9400-bb544f05dc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transform lists into series\n",
    "other_freq = pd.Series(other).value_counts()\n",
    "python_freq = pd.Series(python).value_counts()\n",
    "r_freq = pd.Series(r).value_counts()\n",
    "html_freq = pd.Series(html).value_counts()\n",
    "all_freq = pd.Series(all_words).value_counts()\n",
    "\n",
    "other_freq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d302a57f-79fa-431b-bc00-3665dc49428d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a word_counts data frame we can work with\n",
    "\n",
    "word_counts = (pd.concat([all_freq, other_freq, python_freq, r_freq, html_freq], axis=1, sort=True)\n",
    "                .set_axis(['all', 'other', 'python', 'r', 'html'], axis=1, inplace=False)\n",
    "                .fillna(0)\n",
    "                .apply(lambda s: s.astype(int)))\n",
    "\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61256d64-e7fb-4db2-a091-3e32ef3ff803",
   "metadata": {},
   "source": [
    "### Answer questions about word frequency:\n",
    "\n",
    "**What are the most frequently occuring words?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fbe59f-09fb-48b7-a0c1-93668f10e3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts.sort_values(by='all', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acfb47b-f7e5-4eed-a803-bdd7665e37d2",
   "metadata": {},
   "source": [
    "**Are there any words that uniquely identify one of the coding languages?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a98ef50-7af4-4621-8387-1219c9b29e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([word_counts[word_counts.other == 0].sort_values(by='other').tail(6),\n",
    "           word_counts[word_counts.python == 0].sort_values(by='python').tail(6),\n",
    "           word_counts[word_counts.r == 0].sort_values(by='r').tail(6),\n",
    "           word_counts[word_counts.html == 0].sort_values(by='html').tail(6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2065d6-a1a3-4db3-b4d6-c16b612bd210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out the percentage of spam vs ham\n",
    "(word_counts\n",
    " .assign(p_other=word_counts.other / word_counts['all'],\n",
    "         p_python=word_counts.python / word_counts['all'],\n",
    "         p_r=word_counts.r / word_counts['all'],\n",
    "         p_html=word_counts.html / word_counts['all'])\n",
    " .sort_values(by='all')\n",
    " [['p_other', 'p_python', 'p_r', 'p_html']]\n",
    " .tail(20)\n",
    " .sort_values('p_other')\n",
    " .plot.barh(stacked=True))\n",
    "\n",
    "plt.title('Proportion of Language Word Frequency for the 20 most common words')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29edc417-3c75-4981-8585-a64172c7420e",
   "metadata": {},
   "source": [
    "### Create and Visualize Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe027d9-2e6e-4f5e-bb7e-123d7c6bb260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 20 other\n",
    "top_20_other_bigrams = (pd.Series(nltk.ngrams(other, 2))\n",
    "                      .value_counts()\n",
    "                      .head(20))\n",
    "\n",
    "top_20_other_bigrams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53af233b-b6dd-4c30-8d73-3f5be36d2664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 20 python \n",
    "top_20_python_bigrams = (pd.Series(nltk.ngrams(python, 2))\n",
    "                      .value_counts()\n",
    "                      .head(20))\n",
    "\n",
    "top_20_python_bigrams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20da738-869e-420f-8f9e-d4d3b172fed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 20 r\n",
    "top_20_r_bigrams = (pd.Series(nltk.ngrams(r, 2))\n",
    "                      .value_counts()\n",
    "                      .head(20))\n",
    "\n",
    "top_20_r_bigrams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e794737-3258-448e-a632-69567407752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 20 html\n",
    "top_20_html_bigrams = (pd.Series(nltk.ngrams(html, 2))\n",
    "                      .value_counts()\n",
    "                      .head(20))\n",
    "\n",
    "top_20_html_bigrams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679f7cd2-af63-4e04-be29-23b26d8c2312",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot Top 20 Other\n",
    "\n",
    "top_20_other_bigrams.sort_values().plot.barh(color='pink', width=.9, figsize=(10, 6))\n",
    "\n",
    "plt.title('20 Most frequently occuring other bigrams')\n",
    "plt.ylabel('Bigram')\n",
    "plt.xlabel('# Occurances')\n",
    "\n",
    "# make the labels pretty\n",
    "ticks, _ = plt.yticks()\n",
    "labels = top_20_other_bigrams.reset_index()['index'].apply(lambda t: t[0] + ' ' + t[1])\n",
    "_ = plt.yticks(ticks, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cc7c70-bf96-44c9-94fa-5d8acf8a3d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a wordcloud \n",
    "data = {k[0] + ' ' + k[1]: v for k, v in top_20_other_bigrams.to_dict().items()}\n",
    "img = WordCloud(background_color='white', width=800, height=400).generate_from_frequencies(data)\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e523ac3-d05f-406c-baa9-3709d2f8606a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot Top 20 python\n",
    "\n",
    "top_20_python_bigrams.sort_values().plot.barh(color='pink', width=.9, figsize=(10, 6))\n",
    "\n",
    "plt.title('20 Most frequently occuring jupyter bigrams')\n",
    "plt.ylabel('Bigram')\n",
    "plt.xlabel('# Occurances')\n",
    "\n",
    "# make the labels pretty\n",
    "ticks, _ = plt.yticks()\n",
    "labels = top_20_python_bigrams.reset_index()['index'].apply(lambda t: t[0] + ' ' + t[1])\n",
    "_ = plt.yticks(ticks, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ca9281-71c6-4062-a4b6-c49a341a7b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a wordcloud \n",
    "data = {k[0] + ' ' + k[1]: v for k, v in top_20_python_bigrams.to_dict().items()}\n",
    "img = WordCloud(background_color='white', width=800, height=400).generate_from_frequencies(data)\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad33281b-0f0f-49ef-80fd-414874c9f113",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot Top 20 r\n",
    "\n",
    "top_20_r_bigrams.sort_values().plot.barh(color='pink', width=.9, figsize=(10, 6))\n",
    "\n",
    "plt.title('20 Most frequently occuring r bigrams')\n",
    "plt.ylabel('Bigram')\n",
    "plt.xlabel('# Occurances')\n",
    "\n",
    "# make the labels pretty\n",
    "ticks, _ = plt.yticks()\n",
    "labels = top_20_r_bigrams.reset_index()['index'].apply(lambda t: t[0] + ' ' + t[1])\n",
    "_ = plt.yticks(ticks, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b195239c-475c-4d4d-ba28-6d0e723a6330",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a wordcloud \n",
    "data = {k[0] + ' ' + k[1]: v for k, v in top_20_r_bigrams.to_dict().items()}\n",
    "img = WordCloud(background_color='white', width=800, height=400).generate_from_frequencies(data)\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cf40ec-acd0-4bfd-ac31-680bbb4a091c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot Top 20 html\n",
    "\n",
    "top_20_html_bigrams.sort_values().plot.barh(color='pink', width=.9, figsize=(10, 6))\n",
    "\n",
    "plt.title('20 Most frequently occuring html bigrams')\n",
    "plt.ylabel('Bigram')\n",
    "plt.xlabel('# Occurances')\n",
    "\n",
    "# make the labels pretty\n",
    "ticks, _ = plt.yticks()\n",
    "labels = top_20_html_bigrams.reset_index()['index'].apply(lambda t: t[0] + ' ' + t[1])\n",
    "_ = plt.yticks(ticks, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119a88bb-77a5-4e53-b8ed-aee4589f4171",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a wordcloud \n",
    "data = {k[0] + ' ' + k[1]: v for k, v in top_20_html_bigrams.to_dict().items()}\n",
    "img = WordCloud(background_color='white', width=800, height=400).generate_from_frequencies(data)\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8c6332-097e-423f-9fbd-4121c140a83c",
   "metadata": {},
   "source": [
    "#### Add Other Features to Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b8b2a1-363e-4848-ac91-04cfd925e4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function to get the character count of each doc\n",
    "def get_char_count(string):\n",
    "    \"\"\"\n",
    "    This function will take in a string and return the number of characters in it.\n",
    "    \"\"\"\n",
    "    \n",
    "    return len(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e48c128-01ba-4b5b-849a-1102034bc1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_count(string):\n",
    "    \"\"\"\n",
    "    This function will take in a string and return the number of words in that string.\n",
    "    This function will include repeat words.\n",
    "    \"\"\"\n",
    "    \n",
    "    #Create a list of words separated by a space\n",
    "    words = string.split()\n",
    "    \n",
    "    return len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db418e46-e187-4d41-9277-4a83f52705d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_words(string):\n",
    "    \"\"\"\n",
    "    This function will take in a string and return the number of unique words in that string.\n",
    "    \"\"\"\n",
    "    \n",
    "    words = string.split()\n",
    "    words = set(words)\n",
    "    \n",
    "    return len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc666b8-71b8-43a4-a0a4-4dac95070022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_count(string):\n",
    "    \"\"\"\n",
    "    This function will take in a string and return the number of sentences in that string.\n",
    "    \"\"\"\n",
    "    \n",
    "    sentences = nltk.sent_tokenize(string)\n",
    "    \n",
    "    return len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1736fb82-fcf3-4899-a7f9-af9a728436e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['sentence_count'] = train.original.apply(get_unique_words)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd2388c-098b-48a7-9b26-7a6e6446e7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['char_count'] <=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b63299-8e0e-44c0-acea-b115d0b71d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=train, y='word_count', x='language')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88214dc3-c0f6-4f71-9389-7df1e8400c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=train, y='char_count', x='language')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765e8eba-054a-405e-83f3-a71c55414d3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python397jvsc74a57bd038cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
