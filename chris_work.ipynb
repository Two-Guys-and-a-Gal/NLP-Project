{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import unicodedata\n",
    "import re\n",
    "import env\n",
    "import prepare\n",
    "from matplotlib import style\n",
    "style.use(\"ggplot\")\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mcastrolab/Brazil-Covid19-e0-change</td>\n",
       "      <td>R</td>\n",
       "      <td># Reduction in life expectancy in Brazil after...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jschoeley/de0anim</td>\n",
       "      <td>R</td>\n",
       "      <td># Animated annual changes in life-expectancy\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sychi77/Thoracic_Surgery_Patient_Survival</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td># Thoracic Surgery for Lung Cancer Data Set\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ashtad63/HackerRank-Data-Scientist-Hiring-Test</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td># HackerRank Data Scientist Hiring Test: Predi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OxfordDemSci/ex2020</td>\n",
       "      <td>R</td>\n",
       "      <td>&lt;p align=\"center\"&gt;\\n  &lt;img src=\"https://github...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             repo          language  \\\n",
       "0             mcastrolab/Brazil-Covid19-e0-change                 R   \n",
       "1                               jschoeley/de0anim                 R   \n",
       "2       sychi77/Thoracic_Surgery_Patient_Survival  Jupyter Notebook   \n",
       "3  ashtad63/HackerRank-Data-Scientist-Hiring-Test  Jupyter Notebook   \n",
       "4                             OxfordDemSci/ex2020                 R   \n",
       "\n",
       "                                     readme_contents  \n",
       "0  # Reduction in life expectancy in Brazil after...  \n",
       "1  # Animated annual changes in life-expectancy\\n...  \n",
       "2  # Thoracic Surgery for Lung Cancer Data Set\\n ...  \n",
       "3  # HackerRank Data Scientist Hiring Test: Predi...  \n",
       "4  <p align=\"center\">\\n  <img src=\"https://github...  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make df from data.json\n",
    "df = pd.read_json('data.json')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Jupyter Notebook    10\n",
       "R                    5\n",
       "Stata                3\n",
       "HTML                 2\n",
       "Python               1\n",
       "Objective-C          1\n",
       "Scheme               1\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many rows  have readme_contents with length == 0\n",
    "df[df['readme_contents'].str.len() == 0].language.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language\n",
       "Objective-C         1.000000\n",
       "Scheme              1.000000\n",
       "Stata               0.600000\n",
       "Jupyter Notebook    0.208333\n",
       "R                   0.161290\n",
       "HTML                0.090909\n",
       "Python              0.052632\n",
       "Dart                0.000000\n",
       "Java                0.000000\n",
       "JavaScript          0.000000\n",
       "MATLAB              0.000000\n",
       "Ruby                0.000000\n",
       "Scala               0.000000\n",
       "Shell               0.000000\n",
       "Swift               0.000000\n",
       "TypeScript          0.000000\n",
       "Name: no_readme_contents, dtype: float64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"no_readme_contents\"] = df[\"readme_contents\"].str.len()==0\n",
    "# person of language with no readme_contents\n",
    "df.groupby(\"language\")[\"no_readme_contents\"].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Jupyter Notebook    48\n",
       "R                   31\n",
       "HTML                22\n",
       "Python              19\n",
       "JavaScript          16\n",
       "Stata                5\n",
       "Java                 3\n",
       "Dart                 3\n",
       "Scala                2\n",
       "Swift                2\n",
       "MATLAB               1\n",
       "Shell                1\n",
       "TypeScript           1\n",
       "Ruby                 1\n",
       "Objective-C          1\n",
       "Scheme               1\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many languages are there?\n",
    "df['language'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= prepare.prep_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language\n",
       "other     0.173913\n",
       "Python    0.164179\n",
       "R         0.161290\n",
       "HTML      0.090909\n",
       "Name: no_readme_contents, dtype: float64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"no_readme_contents\"] = df[\"more_clean\"].str.len()==0\n",
    "\n",
    "# person of language with no readme_contents\n",
    "df.groupby(\"language\")[\"no_readme_contents\"].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many rows do we have\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many rows are missing readme data\n",
    "df[df.no_readme_contents==True].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Python    11\n",
       "other      8\n",
       "R          5\n",
       "HTML       2\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.no_readme_contents==True].language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>original</th>\n",
       "      <th>no_readme_contents</th>\n",
       "      <th>more_clean</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>most_common_word</th>\n",
       "      <th>2nd_most_common_word</th>\n",
       "      <th>3rd_most_common_word</th>\n",
       "      <th>4th_most_common_word</th>\n",
       "      <th>5th_most_common_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mcastrolab/Brazil-Covid19-e0-change</td>\n",
       "      <td>R</td>\n",
       "      <td># Reduction in life expectancy in Brazil after...</td>\n",
       "      <td>False</td>\n",
       "      <td>reduction life expectancy brazil covid provide...</td>\n",
       "      <td>2949</td>\n",
       "      <td>352</td>\n",
       "      <td>211</td>\n",
       "      <td>life</td>\n",
       "      <td>expectancy</td>\n",
       "      <td>covid</td>\n",
       "      <td>state</td>\n",
       "      <td>data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jschoeley/de0anim</td>\n",
       "      <td>R</td>\n",
       "      <td># Animated annual changes in life-expectancy\\n...</td>\n",
       "      <td>False</td>\n",
       "      <td>animated annual change lifeexpectancy illustra...</td>\n",
       "      <td>166</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>animated</td>\n",
       "      <td>annual</td>\n",
       "      <td>change</td>\n",
       "      <td>lifeexpectancy</td>\n",
       "      <td>illustration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sychi77/Thoracic_Surgery_Patient_Survival</td>\n",
       "      <td>Python</td>\n",
       "      <td># Thoracic Surgery for Lung Cancer Data Set\\n ...</td>\n",
       "      <td>False</td>\n",
       "      <td>thoracic surgery lung cancer data set uci mach...</td>\n",
       "      <td>2058</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>surgery</td>\n",
       "      <td>f</td>\n",
       "      <td>data</td>\n",
       "      <td>lung</td>\n",
       "      <td>thoracic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ashtad63/HackerRank-Data-Scientist-Hiring-Test</td>\n",
       "      <td>Python</td>\n",
       "      <td># HackerRank Data Scientist Hiring Test: Predi...</td>\n",
       "      <td>False</td>\n",
       "      <td>hackerrank data scientist hiring test predict ...</td>\n",
       "      <td>1011</td>\n",
       "      <td>135</td>\n",
       "      <td>86</td>\n",
       "      <td>country</td>\n",
       "      <td>life</td>\n",
       "      <td>expectancy</td>\n",
       "      <td>must</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OxfordDemSci/ex2020</td>\n",
       "      <td>R</td>\n",
       "      <td>&lt;p align=\"center\"&gt;\\n  &lt;img src=\"https://github...</td>\n",
       "      <td>False</td>\n",
       "      <td>p aligncenter img srchttpsgithubcomoxforddemsc...</td>\n",
       "      <td>2259</td>\n",
       "      <td>234</td>\n",
       "      <td>172</td>\n",
       "      <td>data</td>\n",
       "      <td>relates</td>\n",
       "      <td>code</td>\n",
       "      <td>p</td>\n",
       "      <td>generic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             repo language  \\\n",
       "0             mcastrolab/Brazil-Covid19-e0-change        R   \n",
       "1                               jschoeley/de0anim        R   \n",
       "2       sychi77/Thoracic_Surgery_Patient_Survival   Python   \n",
       "3  ashtad63/HackerRank-Data-Scientist-Hiring-Test   Python   \n",
       "4                             OxfordDemSci/ex2020        R   \n",
       "\n",
       "                                            original  no_readme_contents  \\\n",
       "0  # Reduction in life expectancy in Brazil after...               False   \n",
       "1  # Animated annual changes in life-expectancy\\n...               False   \n",
       "2  # Thoracic Surgery for Lung Cancer Data Set\\n ...               False   \n",
       "3  # HackerRank Data Scientist Hiring Test: Predi...               False   \n",
       "4  <p align=\"center\">\\n  <img src=\"https://github...               False   \n",
       "\n",
       "                                          more_clean  char_count  word_count  \\\n",
       "0  reduction life expectancy brazil covid provide...        2949         352   \n",
       "1  animated annual change lifeexpectancy illustra...         166          16   \n",
       "2  thoracic surgery lung cancer data set uci mach...        2058         234   \n",
       "3  hackerrank data scientist hiring test predict ...        1011         135   \n",
       "4  p aligncenter img srchttpsgithubcomoxforddemsc...        2259         234   \n",
       "\n",
       "   unique_word_count most_common_word 2nd_most_common_word  \\\n",
       "0                211             life           expectancy   \n",
       "1                 16         animated               annual   \n",
       "2                150          surgery                    f   \n",
       "3                 86          country                 life   \n",
       "4                172             data              relates   \n",
       "\n",
       "  3rd_most_common_word 4th_most_common_word 5th_most_common_word  \n",
       "0                covid                state                 data  \n",
       "1               change       lifeexpectancy         illustration  \n",
       "2                 data                 lung             thoracic  \n",
       "3           expectancy                 must                 test  \n",
       "4                 code                    p              generic  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Python    67\n",
       "other     46\n",
       "R         31\n",
       "HTML      22\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many languages are there?\n",
    "df['language'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make vectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "# fit the vectorizer to the data and make df\n",
    "X = tfidf.fit_transform(df['more_clean'])\n",
    "y = df['language']\n",
    "\n",
    "# split data into train and test\n",
    "X_train, X_validate, X_test, y_train, y_validate, y_test = prepare.split_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_accuracy(df, mode):\n",
    "    \"\"\"\n",
    "    Calculate baseline accuracy\n",
    "    \"\"\"\n",
    "    df['mode'] = mode\n",
    "    baseline_accuracy = accuracy_score(df['actual'], df['mode'])\n",
    "    return baseline_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get mode to use as baseline\n",
    "mode = df.language.mode().values[0]\n",
    "#get baseline_accuracy\n",
    "train_baseline = baseline_accuracy(train, mode)\n",
    "validate_baseline = baseline_accuracy(validate, mode)\n",
    "test_baseline = baseline_accuracy(test, mode)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_number</th>\n",
       "      <th>model_type</th>\n",
       "      <th>solver</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>better_than_baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.402174</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_number model_type solver train_accuracy validate_accuracy  \\\n",
       "0     baseline   baseline    NaN       0.402174               0.4   \n",
       "\n",
       "  test_accuracy better_than_baseline  \n",
       "0      0.411765                False  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a df for results\n",
    "results = pd.DataFrame()\n",
    "baseline_model = pd.Series({'model_number':'baseline','model_type':'baseline','solver':np.nan,'train_accuracy':train_baseline,'validate_accuracy':validate_baseline,'test_accuracy':test_baseline, 'better_than_baseline':False})\n",
    "results = pd.concat([results, baseline_model],axis = 0)\n",
    "results.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_number</th>\n",
       "      <th>model_type</th>\n",
       "      <th>solver</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>better_than_baseline</th>\n",
       "      <th>include_jupyter_notebook</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.402174</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.76087</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.76087</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.76087</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.771739</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_number          model_type     solver train_accuracy  \\\n",
       "0     baseline            baseline        NaN       0.402174   \n",
       "1            1  LogisticRegression  liblinear       0.695652   \n",
       "2            2  LogisticRegression      lbfgs        0.76087   \n",
       "3            3  LogisticRegression  newton-cg        0.76087   \n",
       "4            4  LogisticRegression        sag        0.76087   \n",
       "5            5  LogisticRegression       saga       0.771739   \n",
       "\n",
       "  validate_accuracy test_accuracy better_than_baseline  \\\n",
       "0               0.4      0.411765                False   \n",
       "1             0.425      0.441176                 True   \n",
       "2             0.425      0.441176                 True   \n",
       "3             0.425      0.441176                 True   \n",
       "4             0.425      0.441176                 True   \n",
       "5             0.425      0.441176                 True   \n",
       "\n",
       "  include_jupyter_notebook  \n",
       "0                      NaN  \n",
       "1                    False  \n",
       "2                    False  \n",
       "3                    False  \n",
       "4                    False  \n",
       "5                    False  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a df for results\n",
    "results = pd.DataFrame()\n",
    "baseline_model = pd.Series({'model_number':'baseline','model_type':'baseline','solver':np.nan,'train_accuracy':train_baseline,'validate_accuracy':validate_baseline,'test_accuracy':test_baseline, 'better_than_baseline':False})\n",
    "results = pd.concat([results, baseline_model],axis = 0)\n",
    "results.T\n",
    "# make more models varying solver\n",
    "model_number = results.shape[1]\n",
    "for solver in ['liblinear','lbfgs','newton-cg','sag','saga']:\n",
    "    lm = LogisticRegression(solver=solver).fit(X_train, y_train)\n",
    "    # run model on data splits\n",
    "    train['predicted'] = lm.predict(X_train)\n",
    "    validate['predicted'] = lm.predict(X_validate)\n",
    "    test['predicted'] = lm.predict(X_test)\n",
    "    # make results series to add to results df\n",
    "    stats = pd.Series(\n",
    "        {'model_number':model_number,\n",
    "            'model_type':'LogisticRegression',\n",
    "            'solver':solver,\n",
    "            'train_accuracy':accuracy_score(y_train, train['predicted']),\n",
    "            'validate_accuracy':accuracy_score(y_validate, validate['predicted']),\n",
    "            'test_accuracy':accuracy_score(y_test, test['predicted']),\n",
    "            'better_than_baseline':accuracy_score(y_validate, validate['predicted'])>validate_baseline,\n",
    "            'include_jupyter_notebook':'Jupyter Notebook' in df.language\n",
    "        })\n",
    "    # add to results df\n",
    "    results = pd.concat([results, stats], axis = 1)\n",
    "    model_number += 1\n",
    "\n",
    "results.T.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_low_count_languages(df, threshold=3):\n",
    "    \"\"\"\n",
    "    Drop languages with less than threshold number of entries\n",
    "    \"\"\"\n",
    "    languages = (df['language'].value_counts()>3)\n",
    "    to_keep = languages[languages==True].index.tolist()\n",
    "    df = df[df['language'].isin(to_keep)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models(drop_jupyter=True, drop_low_count_langs=True, n_languages=3):\n",
    "    \"\"\"\n",
    "    Run models on data varying solver\n",
    "    \"\"\"\n",
    "    #get raw data\n",
    "    df = pd.read_json('data.json')\n",
    "    # clean data\n",
    "    df['more_clean'] = df['readme_contents'].apply(prepare.more_clean)\n",
    "    if drop_jupyter:\n",
    "        df = df[df['language'] != 'Jupyter Notebook']\n",
    "    if drop_low_count_langs:\n",
    "        df = drop_low_count_languages(df)\n",
    "    df = prepare.keep_top_n_languages(df, n_languages=n_languages)\n",
    "    # make vectorizer\n",
    "    tfidf = TfidfVectorizer()\n",
    "    # fit the vectorizer to the data and make df\n",
    "    X = tfidf.fit_transform(df['more_clean'])\n",
    "    y = df['language']\n",
    "\n",
    "    # split data into train and test\n",
    "    X_train, X_validate, X_test, y_train, y_validate, y_test = prepare.split_data(X, y)\n",
    "    train = pd.DataFrame(dict(actual=y_train))\n",
    "    validate = pd.DataFrame(dict(actual=y_validate))\n",
    "    test = pd.DataFrame(dict(actual=y_test))\n",
    "    #get mode to use as baseline\n",
    "    mode = df.language.mode().values[0]\n",
    "    #get baseline_accuracy\n",
    "    train_baseline = baseline_accuracy(train, mode)\n",
    "    validate_baseline = baseline_accuracy(validate, mode)\n",
    "    test_baseline = baseline_accuracy(test, mode)\n",
    "    # make a df for results\n",
    "    results = pd.DataFrame()\n",
    "    # make baseline model\n",
    "    baseline_model = pd.Series({'model_number':'baseline','model_type':'baseline','solver':np.nan,'train_accuracy':train_baseline,'validate_accuracy':validate_baseline,'test_accuracy':test_baseline, 'better_than_baseline':False})\n",
    "    # add baseline model to results df\n",
    "    results = pd.concat([results, baseline_model],axis = 0)\n",
    "    # make more models varying solver\n",
    "    model_number = results.shape[1]\n",
    "    for solver in ['liblinear','lbfgs','newton-cg','sag','saga']:\n",
    "        lm = LogisticRegression(solver=solver).fit(X_train, y_train)\n",
    "        # run model on data splits\n",
    "        train['predicted'] = lm.predict(X_train)\n",
    "        validate['predicted'] = lm.predict(X_validate)\n",
    "        test['predicted'] = lm.predict(X_test)\n",
    "        # make results series to add to results df\n",
    "        stats = pd.Series(\n",
    "        {'model_number':model_number,\n",
    "            'model_type':'LogisticRegression',\n",
    "            'solver':solver,\n",
    "            'train_accuracy':accuracy_score(y_train, train['predicted']),\n",
    "            'validate_accuracy':accuracy_score(y_validate, validate['predicted']),\n",
    "            'test_accuracy':accuracy_score(y_test, test['predicted']),\n",
    "            'better_than_baseline':accuracy_score(y_validate, validate['predicted'])>validate_baseline,\n",
    "            'drop_jupyter':drop_jupyter,\n",
    "            'drop_low_count_languages':drop_low_count_langs,\n",
    "            'n_languages':n_languages\n",
    "        })\n",
    "        # add to results df\n",
    "        results = pd.concat([results, stats], axis = 1)\n",
    "        model_number += 1\n",
    "\n",
    "    return results.T.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_number</th>\n",
       "      <th>model_type</th>\n",
       "      <th>solver</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>better_than_baseline</th>\n",
       "      <th>drop_jupyter</th>\n",
       "      <th>drop_low_count_languages</th>\n",
       "      <th>n_languages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_number          model_type     solver train_accuracy  \\\n",
       "0     baseline            baseline        NaN       0.333333   \n",
       "1            1  LogisticRegression  liblinear       0.941176   \n",
       "2            2  LogisticRegression      lbfgs       0.941176   \n",
       "3            3  LogisticRegression  newton-cg       0.941176   \n",
       "4            4  LogisticRegression        sag       0.941176   \n",
       "5            5  LogisticRegression       saga       0.941176   \n",
       "\n",
       "  validate_accuracy test_accuracy better_than_baseline drop_jupyter  \\\n",
       "0          0.347826      0.315789                False          NaN   \n",
       "1          0.347826      0.315789                False         True   \n",
       "2          0.347826      0.315789                False         True   \n",
       "3          0.347826      0.315789                False         True   \n",
       "4          0.347826      0.315789                False         True   \n",
       "5          0.347826      0.315789                False         True   \n",
       "\n",
       "  drop_low_count_languages n_languages  \n",
       "0                      NaN         NaN  \n",
       "1                     True           3  \n",
       "2                     True           3  \n",
       "3                     True           3  \n",
       "4                     True           3  \n",
       "5                     True           3  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_models(drop_jupyter=True, drop_low_count_langs=True, n_languages=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_number</th>\n",
       "      <th>model_type</th>\n",
       "      <th>solver</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>better_than_baseline</th>\n",
       "      <th>drop_jupyter</th>\n",
       "      <th>drop_low_count_languages</th>\n",
       "      <th>n_languages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.910256</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_number          model_type     solver train_accuracy  \\\n",
       "0     baseline            baseline        NaN       0.346154   \n",
       "1            1  LogisticRegression  liblinear       0.833333   \n",
       "2            2  LogisticRegression      lbfgs       0.884615   \n",
       "3            3  LogisticRegression  newton-cg       0.884615   \n",
       "4            4  LogisticRegression        sag       0.884615   \n",
       "5            5  LogisticRegression       saga       0.910256   \n",
       "\n",
       "  validate_accuracy test_accuracy better_than_baseline drop_jupyter  \\\n",
       "0          0.323529      0.344828                False          NaN   \n",
       "1          0.382353      0.310345                 True        False   \n",
       "2          0.382353      0.310345                 True        False   \n",
       "3          0.382353      0.310345                 True        False   \n",
       "4          0.382353      0.310345                 True        False   \n",
       "5          0.382353      0.310345                 True        False   \n",
       "\n",
       "  drop_low_count_languages n_languages  \n",
       "0                      NaN         NaN  \n",
       "1                     True           3  \n",
       "2                     True           3  \n",
       "3                     True           3  \n",
       "4                     True           3  \n",
       "5                     True           3  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_models(drop_jupyter=False, drop_low_count_langs=True, n_languages=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_number</th>\n",
       "      <th>model_type</th>\n",
       "      <th>solver</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>better_than_baseline</th>\n",
       "      <th>drop_jupyter</th>\n",
       "      <th>drop_low_count_languages</th>\n",
       "      <th>n_languages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.73913</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.815217</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.815217</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.815217</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.836957</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_number          model_type     solver train_accuracy  \\\n",
       "0     baseline            baseline        NaN       0.391304   \n",
       "1            1  LogisticRegression  liblinear        0.73913   \n",
       "2            2  LogisticRegression      lbfgs       0.815217   \n",
       "3            3  LogisticRegression  newton-cg       0.815217   \n",
       "4            4  LogisticRegression        sag       0.815217   \n",
       "5            5  LogisticRegression       saga       0.836957   \n",
       "\n",
       "  validate_accuracy test_accuracy better_than_baseline drop_jupyter  \\\n",
       "0               0.4      0.382353                False          NaN   \n",
       "1             0.425      0.441176                 True        False   \n",
       "2             0.475      0.441176                 True        False   \n",
       "3             0.475      0.441176                 True        False   \n",
       "4             0.475      0.441176                 True        False   \n",
       "5               0.5      0.441176                 True        False   \n",
       "\n",
       "  drop_low_count_languages n_languages  \n",
       "0                      NaN         NaN  \n",
       "1                    False           3  \n",
       "2                    False           3  \n",
       "3                    False           3  \n",
       "4                    False           3  \n",
       "5                    False           3  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_models(drop_jupyter=False, drop_low_count_langs=False, n_languages=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models2(drop_jupyter=True, drop_low_count_langs=True, drop_empty_readmes=True, n_languages=3):\n",
    "    \"\"\"\n",
    "    Run models on data varying solver and C value\n",
    "    \"\"\"\n",
    "    #get raw data\n",
    "    df = pd.read_json('data.json')\n",
    "    # clean data\n",
    "    df['more_clean'] = df['readme_contents'].apply(prepare.more_clean)\n",
    "    if drop_jupyter:\n",
    "        df = df[df['language'] != 'Jupyter Notebook']\n",
    "    if drop_low_count_langs:\n",
    "        df = drop_low_count_languages(df)\n",
    "    if drop_empty_readmes:\n",
    "        df = df[df['more_clean'] != '']\n",
    "    df = prepare.keep_top_n_languages(df, n_languages=n_languages)\n",
    "    # make vectorizer\n",
    "    tfidf = TfidfVectorizer()\n",
    "    # fit the vectorizer to the data and make df\n",
    "    X = tfidf.fit_transform(df['more_clean'])\n",
    "    y = df['language']\n",
    "\n",
    "    # split data into train and test\n",
    "    X_train, X_validate, X_test, y_train, y_validate, y_test = prepare.split_data(X, y)\n",
    "    train = pd.DataFrame(dict(actual=y_train))\n",
    "    validate = pd.DataFrame(dict(actual=y_validate))\n",
    "    test = pd.DataFrame(dict(actual=y_test))\n",
    "    #get mode to use as baseline\n",
    "    mode = df.language.mode().values[0]\n",
    "    #get baseline_accuracy\n",
    "    train_baseline = baseline_accuracy(train, mode)\n",
    "    validate_baseline = baseline_accuracy(validate, mode)\n",
    "    test_baseline = baseline_accuracy(test, mode)\n",
    "    # make a df for results\n",
    "    results = pd.DataFrame()\n",
    "    # make baseline model\n",
    "    baseline_model = pd.Series({'model_number':'baseline','model_type':'baseline','solver':np.nan,'train_accuracy':train_baseline,'validate_accuracy':validate_baseline,'test_accuracy':test_baseline, 'better_than_baseline':False})\n",
    "    # add baseline model to results df\n",
    "    results = pd.concat([results, baseline_model],axis = 0)\n",
    "    # make more models varying solver\n",
    "    model_number = results.shape[1]\n",
    "    c_values = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "    for solver in ['liblinear','lbfgs','newton-cg','sag','saga']:\n",
    "        for c in c_values:\n",
    "            #make the model\n",
    "            lm = LogisticRegression(C=c, solver=solver).fit(X_train, y_train)\n",
    "            # run model on data splits\n",
    "            train['predicted'] = lm.predict(X_train)\n",
    "            validate['predicted'] = lm.predict(X_validate)\n",
    "            test['predicted'] = lm.predict(X_test)\n",
    "            # make results series to add to results df\n",
    "            stats = pd.Series(\n",
    "            {'model_number':model_number,\n",
    "                'model_type':'LogisticRegression',\n",
    "                'solver':solver,\n",
    "                'C':c,\n",
    "                'train_accuracy':accuracy_score(y_train, train['predicted']),\n",
    "                'validate_accuracy':accuracy_score(y_validate, validate['predicted']),\n",
    "                'test_accuracy':accuracy_score(y_test, test['predicted']),\n",
    "                'better_than_baseline':accuracy_score(y_validate, validate['predicted'])>validate_baseline,\n",
    "                'drop_jupyter':drop_jupyter,\n",
    "                'drop_low_count_languages':drop_low_count_langs,\n",
    "                'drop_empty_readmes':drop_empty_readmes,\n",
    "                'n_languages':n_languages\n",
    "            })\n",
    "            # add to results df\n",
    "            results = pd.concat([results, stats], axis = 1)\n",
    "            model_number += 1\n",
    "\n",
    "    return results.T.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_number</th>\n",
       "      <th>model_type</th>\n",
       "      <th>solver</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>better_than_baseline</th>\n",
       "      <th>C</th>\n",
       "      <th>drop_jupyter</th>\n",
       "      <th>drop_low_count_languages</th>\n",
       "      <th>n_languages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>True</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>True</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>True</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_number          model_type     solver train_accuracy  \\\n",
       "21           21  LogisticRegression  newton-cg       0.941176   \n",
       "14           14  LogisticRegression      lbfgs       0.941176   \n",
       "7             7  LogisticRegression  liblinear       0.941176   \n",
       "\n",
       "   validate_accuracy test_accuracy better_than_baseline     C drop_jupyter  \\\n",
       "21          0.434783      0.421053                 True  1000         True   \n",
       "14          0.434783      0.421053                 True  1000         True   \n",
       "7           0.434783      0.421053                 True  1000         True   \n",
       "\n",
       "   drop_low_count_languages n_languages  \n",
       "21                     True           3  \n",
       "14                     True           3  \n",
       "7                      True           3  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_models2(drop_jupyter=True, drop_low_count_langs=True, n_languages=3).sort_values('validate_accuracy', ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_number</th>\n",
       "      <th>model_type</th>\n",
       "      <th>solver</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>better_than_baseline</th>\n",
       "      <th>C</th>\n",
       "      <th>drop_jupyter</th>\n",
       "      <th>drop_low_count_languages</th>\n",
       "      <th>n_languages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>True</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>True</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>True</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_number          model_type     solver train_accuracy  \\\n",
       "28           28  LogisticRegression        sag       0.948718   \n",
       "7             7  LogisticRegression  liblinear       0.948718   \n",
       "35           35  LogisticRegression       saga       0.948718   \n",
       "\n",
       "   validate_accuracy test_accuracy better_than_baseline     C drop_jupyter  \\\n",
       "28          0.470588      0.413793                 True  1000        False   \n",
       "7           0.441176      0.448276                 True  1000        False   \n",
       "35          0.411765      0.448276                 True  1000        False   \n",
       "\n",
       "   drop_low_count_languages n_languages  \n",
       "28                     True           3  \n",
       "7                      True           3  \n",
       "35                     True           3  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_models2(drop_jupyter=False, drop_low_count_langs=True, n_languages=3).sort_values('validate_accuracy', ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_number</th>\n",
       "      <th>model_type</th>\n",
       "      <th>solver</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>better_than_baseline</th>\n",
       "      <th>C</th>\n",
       "      <th>drop_jupyter</th>\n",
       "      <th>drop_low_count_languages</th>\n",
       "      <th>n_languages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.815217</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.923913</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_number          model_type     solver train_accuracy  \\\n",
       "5             5  LogisticRegression  liblinear       0.913043   \n",
       "18           18  LogisticRegression  newton-cg       0.815217   \n",
       "26           26  LogisticRegression        sag       0.923913   \n",
       "\n",
       "   validate_accuracy test_accuracy better_than_baseline   C drop_jupyter  \\\n",
       "5                0.5           0.5                 True  10        False   \n",
       "18             0.475      0.441176                 True   1        False   \n",
       "26             0.475           0.5                 True  10        False   \n",
       "\n",
       "   drop_low_count_languages n_languages  \n",
       "5                     False           3  \n",
       "18                    False           3  \n",
       "26                    False           3  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_models2(drop_jupyter=False, drop_low_count_langs=False, n_languages=3).sort_values('validate_accuracy', ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_number</th>\n",
       "      <th>model_type</th>\n",
       "      <th>solver</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>better_than_baseline</th>\n",
       "      <th>C</th>\n",
       "      <th>drop_jupyter</th>\n",
       "      <th>drop_low_count_languages</th>\n",
       "      <th>drop_empty_readmes</th>\n",
       "      <th>n_languages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>sag</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_number          model_type     solver train_accuracy  \\\n",
       "27           27  LogisticRegression        sag            1.0   \n",
       "6             6  LogisticRegression  liblinear            1.0   \n",
       "7             7  LogisticRegression  liblinear            1.0   \n",
       "\n",
       "   validate_accuracy test_accuracy better_than_baseline     C drop_jupyter  \\\n",
       "27          0.558824      0.535714                 True   100        False   \n",
       "6           0.558824           0.5                 True   100        False   \n",
       "7           0.558824           0.5                 True  1000        False   \n",
       "\n",
       "   drop_low_count_languages drop_empty_readmes n_languages  \n",
       "27                    False               True           3  \n",
       "6                     False               True           3  \n",
       "7                     False               True           3  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_models2(drop_jupyter=False, drop_low_count_langs=False, drop_empty_readmes=True, n_languages=3).sort_values(['validate_accuracy','test_accuracy'], ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moved to prepare.py\n",
    "# \n",
    "# # which word is the most common in the string\n",
    "# def n_most_common_word(string, n=1):\n",
    "#     \"\"\"\n",
    "#     Return the most common word in a string\n",
    "#     \"\"\"\n",
    "#     words = string.split()\n",
    "#     if len(words) < n:\n",
    "#         return ''\n",
    "#     word_counts = Counter(words)\n",
    "#     return word_counts.most_common(n)[n-1][0]\n",
    "\n",
    "# n_most_common_word(df.more_clean[1],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models3():\n",
    "    \"\"\"\n",
    "    Run models on data varying solver and C value\n",
    "    \"\"\"\n",
    "    #get raw data\n",
    "    df = pd.read_json('data.json')\n",
    "    df = prepare.prepare_data(df)\n",
    "    # make vectorizer\n",
    "    tfidf = TfidfVectorizer()\n",
    "    # fit the vectorizer to the data and make df\n",
    "    X = tfidf.fit_transform(df['more_clean'])\n",
    "    y = df['language']\n",
    "\n",
    "    # split data into train and test\n",
    "    X_train, X_validate, X_test, y_train, y_validate, y_test = prepare.split_data(X, y)\n",
    "    train = pd.DataFrame(dict(actual=y_train))\n",
    "    validate = pd.DataFrame(dict(actual=y_validate))\n",
    "    test = pd.DataFrame(dict(actual=y_test))\n",
    "    #get mode to use as baseline\n",
    "    mode = df.language.mode().values[0]\n",
    "    #get baseline_accuracy\n",
    "    train_baseline = baseline_accuracy(train, mode)\n",
    "    validate_baseline = baseline_accuracy(validate, mode)\n",
    "    test_baseline = baseline_accuracy(test, mode)\n",
    "    # make a df for results\n",
    "    results = pd.DataFrame()\n",
    "    # make baseline model\n",
    "    baseline_model = pd.Series({'model_number':'baseline','model_type':'baseline','solver':np.nan,'train_accuracy':train_baseline,'validate_accuracy':validate_baseline,'test_accuracy':test_baseline, 'better_than_baseline':False})\n",
    "    # add baseline model to results df\n",
    "    results = pd.concat([results, baseline_model],axis = 0)\n",
    "    # make more models varying solver\n",
    "    model_number = results.shape[1]\n",
    "    c_values = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "    for solver in ['liblinear','lbfgs','newton-cg','sag','saga']:\n",
    "        for c in c_values:\n",
    "            #make the model\n",
    "            lm = LogisticRegression(C=c, solver=solver).fit(X_train, y_train)\n",
    "            # run model on data splits\n",
    "            train['predicted'] = lm.predict(X_train)\n",
    "            validate['predicted'] = lm.predict(X_validate)\n",
    "            test['predicted'] = lm.predict(X_test)\n",
    "            # make results series to add to results df\n",
    "            stats = pd.Series(\n",
    "            {'model_number':model_number,\n",
    "                'model_type':'LogisticRegression',\n",
    "                'solver':solver,\n",
    "                'C':c,\n",
    "                'train_accuracy':accuracy_score(y_train, train['predicted']),\n",
    "                'validate_accuracy':accuracy_score(y_validate, validate['predicted']),\n",
    "                'test_accuracy':accuracy_score(y_test, test['predicted']),\n",
    "                'better_than_baseline':accuracy_score(y_validate, validate['predicted'])>validate_baseline,\n",
    "            })\n",
    "            # add to results df\n",
    "            results = pd.concat([results, stats], axis = 1)\n",
    "            model_number += 1\n",
    "\n",
    "    return results.T.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Jupyter Notebook    48\n",
       "R                   31\n",
       "HTML                22\n",
       "Python              19\n",
       "JavaScript          16\n",
       "Stata                5\n",
       "Java                 3\n",
       "Dart                 3\n",
       "Scala                2\n",
       "Swift                2\n",
       "MATLAB               1\n",
       "Shell                1\n",
       "TypeScript           1\n",
       "Ruby                 1\n",
       "Objective-C          1\n",
       "Scheme               1\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('data.json')\n",
    "df.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Python    67\n",
       "other     46\n",
       "R         31\n",
       "HTML      22\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = prepare.prep_data(df)\n",
    "df.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>original</th>\n",
       "      <th>more_clean</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>most_common_word</th>\n",
       "      <th>2nd_most_common_word</th>\n",
       "      <th>3rd_most_common_word</th>\n",
       "      <th>4th_most_common_word</th>\n",
       "      <th>5th_most_common_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mcastrolab/Brazil-Covid19-e0-change</td>\n",
       "      <td>R</td>\n",
       "      <td># Reduction in life expectancy in Brazil after...</td>\n",
       "      <td>reduction life expectancy brazil covid provide...</td>\n",
       "      <td>2949</td>\n",
       "      <td>352</td>\n",
       "      <td>211</td>\n",
       "      <td>life</td>\n",
       "      <td>expectancy</td>\n",
       "      <td>covid</td>\n",
       "      <td>state</td>\n",
       "      <td>data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jschoeley/de0anim</td>\n",
       "      <td>R</td>\n",
       "      <td># Animated annual changes in life-expectancy\\n...</td>\n",
       "      <td>animated annual change lifeexpectancy illustra...</td>\n",
       "      <td>166</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>animated</td>\n",
       "      <td>annual</td>\n",
       "      <td>change</td>\n",
       "      <td>lifeexpectancy</td>\n",
       "      <td>illustration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sychi77/Thoracic_Surgery_Patient_Survival</td>\n",
       "      <td>Python</td>\n",
       "      <td># Thoracic Surgery for Lung Cancer Data Set\\n ...</td>\n",
       "      <td>thoracic surgery lung cancer data set uci mach...</td>\n",
       "      <td>2058</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>surgery</td>\n",
       "      <td>f</td>\n",
       "      <td>data</td>\n",
       "      <td>lung</td>\n",
       "      <td>thoracic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ashtad63/HackerRank-Data-Scientist-Hiring-Test</td>\n",
       "      <td>Python</td>\n",
       "      <td># HackerRank Data Scientist Hiring Test: Predi...</td>\n",
       "      <td>hackerrank data scientist hiring test predict ...</td>\n",
       "      <td>1011</td>\n",
       "      <td>135</td>\n",
       "      <td>86</td>\n",
       "      <td>country</td>\n",
       "      <td>life</td>\n",
       "      <td>expectancy</td>\n",
       "      <td>must</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OxfordDemSci/ex2020</td>\n",
       "      <td>R</td>\n",
       "      <td>&lt;p align=\"center\"&gt;\\n  &lt;img src=\"https://github...</td>\n",
       "      <td>p aligncenter img srchttpsgithubcomoxforddemsc...</td>\n",
       "      <td>2259</td>\n",
       "      <td>234</td>\n",
       "      <td>172</td>\n",
       "      <td>data</td>\n",
       "      <td>relates</td>\n",
       "      <td>code</td>\n",
       "      <td>p</td>\n",
       "      <td>generic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>DorukTaneli/scheme-database</td>\n",
       "      <td>other</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>dashamet/Gapminder</td>\n",
       "      <td>HTML</td>\n",
       "      <td># GDP Per Capita vs. Life Expectancy \\n\\n* `ga...</td>\n",
       "      <td>gdp per caput v life expectancy gapminderrmd c...</td>\n",
       "      <td>256</td>\n",
       "      <td>37</td>\n",
       "      <td>28</td>\n",
       "      <td>continent</td>\n",
       "      <td>gdp</td>\n",
       "      <td>per</td>\n",
       "      <td>caput</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>ckraft-bot/GDHappiness</td>\n",
       "      <td>Python</td>\n",
       "      <td># GDHappiness\\nLooking at the 2021 data which ...</td>\n",
       "      <td>gdhappiness looking data country happiest vari...</td>\n",
       "      <td>131</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>life</td>\n",
       "      <td>gdhappiness</td>\n",
       "      <td>looking</td>\n",
       "      <td>data</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>johnwhittenstudio/project-5</td>\n",
       "      <td>other</td>\n",
       "      <td># Super Galactic Age Calculator\\n\\n## by _**Jo...</td>\n",
       "      <td>super galactic age calculator john whitten dec...</td>\n",
       "      <td>3253</td>\n",
       "      <td>436</td>\n",
       "      <td>231</td>\n",
       "      <td>year</td>\n",
       "      <td>age</td>\n",
       "      <td>project</td>\n",
       "      <td>user</td>\n",
       "      <td>life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>arthurtham/octopet</td>\n",
       "      <td>other</td>\n",
       "      <td>![Octopet](https://media.giphy.com/media/1hoKk...</td>\n",
       "      <td>octopethttpsmediagiphycommediahokkbnsbxvyhispe...</td>\n",
       "      <td>1835</td>\n",
       "      <td>248</td>\n",
       "      <td>182</td>\n",
       "      <td>octocat</td>\n",
       "      <td>app</td>\n",
       "      <td>android</td>\n",
       "      <td>unhealthy</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               repo language  \\\n",
       "0               mcastrolab/Brazil-Covid19-e0-change        R   \n",
       "1                                 jschoeley/de0anim        R   \n",
       "2         sychi77/Thoracic_Surgery_Patient_Survival   Python   \n",
       "3    ashtad63/HackerRank-Data-Scientist-Hiring-Test   Python   \n",
       "4                               OxfordDemSci/ex2020        R   \n",
       "..                                              ...      ...   \n",
       "161                     DorukTaneli/scheme-database    other   \n",
       "162                              dashamet/Gapminder     HTML   \n",
       "163                          ckraft-bot/GDHappiness   Python   \n",
       "164                     johnwhittenstudio/project-5    other   \n",
       "165                              arthurtham/octopet    other   \n",
       "\n",
       "                                              original  \\\n",
       "0    # Reduction in life expectancy in Brazil after...   \n",
       "1    # Animated annual changes in life-expectancy\\n...   \n",
       "2    # Thoracic Surgery for Lung Cancer Data Set\\n ...   \n",
       "3    # HackerRank Data Scientist Hiring Test: Predi...   \n",
       "4    <p align=\"center\">\\n  <img src=\"https://github...   \n",
       "..                                                 ...   \n",
       "161                                                      \n",
       "162  # GDP Per Capita vs. Life Expectancy \\n\\n* `ga...   \n",
       "163  # GDHappiness\\nLooking at the 2021 data which ...   \n",
       "164  # Super Galactic Age Calculator\\n\\n## by _**Jo...   \n",
       "165  ![Octopet](https://media.giphy.com/media/1hoKk...   \n",
       "\n",
       "                                            more_clean  char_count  \\\n",
       "0    reduction life expectancy brazil covid provide...        2949   \n",
       "1    animated annual change lifeexpectancy illustra...         166   \n",
       "2    thoracic surgery lung cancer data set uci mach...        2058   \n",
       "3    hackerrank data scientist hiring test predict ...        1011   \n",
       "4    p aligncenter img srchttpsgithubcomoxforddemsc...        2259   \n",
       "..                                                 ...         ...   \n",
       "161                                                              0   \n",
       "162  gdp per caput v life expectancy gapminderrmd c...         256   \n",
       "163  gdhappiness looking data country happiest vari...         131   \n",
       "164  super galactic age calculator john whitten dec...        3253   \n",
       "165  octopethttpsmediagiphycommediahokkbnsbxvyhispe...        1835   \n",
       "\n",
       "     word_count  unique_word_count most_common_word 2nd_most_common_word  \\\n",
       "0           352                211             life           expectancy   \n",
       "1            16                 16         animated               annual   \n",
       "2           234                150          surgery                    f   \n",
       "3           135                 86          country                 life   \n",
       "4           234                172             data              relates   \n",
       "..          ...                ...              ...                  ...   \n",
       "161           0                  0                                         \n",
       "162          37                 28        continent                  gdp   \n",
       "163          16                 15             life          gdhappiness   \n",
       "164         436                231             year                  age   \n",
       "165         248                182          octocat                  app   \n",
       "\n",
       "    3rd_most_common_word 4th_most_common_word 5th_most_common_word  \n",
       "0                  covid                state                 data  \n",
       "1                 change       lifeexpectancy         illustration  \n",
       "2                   data                 lung             thoracic  \n",
       "3             expectancy                 must                 test  \n",
       "4                   code                    p              generic  \n",
       "..                   ...                  ...                  ...  \n",
       "161                                                                 \n",
       "162                  per                caput                    v  \n",
       "163              looking                 data              country  \n",
       "164              project                 user                 life  \n",
       "165              android            unhealthy              healthy  \n",
       "\n",
       "[166 rows x 12 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>original</th>\n",
       "      <th>more_clean</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>most_common_word</th>\n",
       "      <th>2nd_most_common_word</th>\n",
       "      <th>3rd_most_common_word</th>\n",
       "      <th>4th_most_common_word</th>\n",
       "      <th>5th_most_common_word</th>\n",
       "      <th>unique_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mcastrolab/Brazil-Covid19-e0-change</td>\n",
       "      <td>R</td>\n",
       "      <td># Reduction in life expectancy in Brazil after...</td>\n",
       "      <td>reduction life expectancy brazil covid provide...</td>\n",
       "      <td>2949</td>\n",
       "      <td>352</td>\n",
       "      <td>211</td>\n",
       "      <td>life</td>\n",
       "      <td>expectancy</td>\n",
       "      <td>covid</td>\n",
       "      <td>state</td>\n",
       "      <td>data</td>\n",
       "      <td>rsrio httpsdoiorgsz cassiomturrahttpstwitterco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jschoeley/de0anim</td>\n",
       "      <td>R</td>\n",
       "      <td># Animated annual changes in life-expectancy\\n...</td>\n",
       "      <td>animated annual change lifeexpectancy illustra...</td>\n",
       "      <td>166</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>animated</td>\n",
       "      <td>annual</td>\n",
       "      <td>change</td>\n",
       "      <td>lifeexpectancy</td>\n",
       "      <td>illustration</td>\n",
       "      <td>illustration life paper quantifying covid expe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sychi77/Thoracic_Surgery_Patient_Survival</td>\n",
       "      <td>Python</td>\n",
       "      <td># Thoracic Surgery for Lung Cancer Data Set\\n ...</td>\n",
       "      <td>thoracic surgery lung cancer data set uci mach...</td>\n",
       "      <td>2058</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>surgery</td>\n",
       "      <td>f</td>\n",
       "      <td>data</td>\n",
       "      <td>lung</td>\n",
       "      <td>thoracic</td>\n",
       "      <td>blood asthma pulmonary death powerpoint jupyte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ashtad63/HackerRank-Data-Scientist-Hiring-Test</td>\n",
       "      <td>Python</td>\n",
       "      <td># HackerRank Data Scientist Hiring Test: Predi...</td>\n",
       "      <td>hackerrank data scientist hiring test predict ...</td>\n",
       "      <td>1011</td>\n",
       "      <td>135</td>\n",
       "      <td>86</td>\n",
       "      <td>country</td>\n",
       "      <td>life</td>\n",
       "      <td>expectancy</td>\n",
       "      <td>must</td>\n",
       "      <td>test</td>\n",
       "      <td>name two real first research evaluating differ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OxfordDemSci/ex2020</td>\n",
       "      <td>R</td>\n",
       "      <td>&lt;p align=\"center\"&gt;\\n  &lt;img src=\"https://github...</td>\n",
       "      <td>p aligncenter img srchttpsgithubcomoxforddemsc...</td>\n",
       "      <td>2259</td>\n",
       "      <td>234</td>\n",
       "      <td>172</td>\n",
       "      <td>data</td>\n",
       "      <td>relates</td>\n",
       "      <td>code</td>\n",
       "      <td>p</td>\n",
       "      <td>generic</td>\n",
       "      <td>running without paper ermisch dependency popul...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             repo language  \\\n",
       "0             mcastrolab/Brazil-Covid19-e0-change        R   \n",
       "1                               jschoeley/de0anim        R   \n",
       "2       sychi77/Thoracic_Surgery_Patient_Survival   Python   \n",
       "3  ashtad63/HackerRank-Data-Scientist-Hiring-Test   Python   \n",
       "4                             OxfordDemSci/ex2020        R   \n",
       "\n",
       "                                            original  \\\n",
       "0  # Reduction in life expectancy in Brazil after...   \n",
       "1  # Animated annual changes in life-expectancy\\n...   \n",
       "2  # Thoracic Surgery for Lung Cancer Data Set\\n ...   \n",
       "3  # HackerRank Data Scientist Hiring Test: Predi...   \n",
       "4  <p align=\"center\">\\n  <img src=\"https://github...   \n",
       "\n",
       "                                          more_clean  char_count  word_count  \\\n",
       "0  reduction life expectancy brazil covid provide...        2949         352   \n",
       "1  animated annual change lifeexpectancy illustra...         166          16   \n",
       "2  thoracic surgery lung cancer data set uci mach...        2058         234   \n",
       "3  hackerrank data scientist hiring test predict ...        1011         135   \n",
       "4  p aligncenter img srchttpsgithubcomoxforddemsc...        2259         234   \n",
       "\n",
       "   unique_word_count most_common_word 2nd_most_common_word  \\\n",
       "0                211             life           expectancy   \n",
       "1                 16         animated               annual   \n",
       "2                150          surgery                    f   \n",
       "3                 86          country                 life   \n",
       "4                172             data              relates   \n",
       "\n",
       "  3rd_most_common_word 4th_most_common_word 5th_most_common_word  \\\n",
       "0                covid                state                 data   \n",
       "1               change       lifeexpectancy         illustration   \n",
       "2                 data                 lung             thoracic   \n",
       "3           expectancy                 must                 test   \n",
       "4                 code                    p              generic   \n",
       "\n",
       "                                        unique_words  \n",
       "0  rsrio httpsdoiorgsz cassiomturrahttpstwitterco...  \n",
       "1  illustration life paper quantifying covid expe...  \n",
       "2  blood asthma pulmonary death powerpoint jupyte...  \n",
       "3  name two real first research evaluating differ...  \n",
       "4  running without paper ermisch dependency popul...  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_unique_words(text):\n",
    "    \"\"\"\n",
    "    Get unique words in dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    words = text.split()\n",
    "    unique_words = set(words)\n",
    "    new_string = ' '.join(unique_words)\n",
    "    return new_string\n",
    "\n",
    "df['unique_words'] = df['more_clean'].apply(get_unique_words)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_unique_words(text, threshold=5):\n",
    "    \"\"\"\n",
    "    Get common unique words in dataframe, aka words that occur in multiple readme's\n",
    "    a word must appear in at least threshold readmes to be considered a common word\n",
    "    \"\"\"\n",
    "\n",
    "    words = text.split()\n",
    "    counter = Counter(words)\n",
    "    common_unique_words = [word for word, count in counter.items() if count >= threshold]\n",
    "    new_string = ' '.join(common_unique_words)\n",
    "    return new_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>all_words</th>\n",
       "      <th>unique_words</th>\n",
       "      <th>common_unique_words</th>\n",
       "      <th>n_words</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>mean_word_count</th>\n",
       "      <th>median_word_count</th>\n",
       "      <th>most_common_word</th>\n",
       "      <th>2nd_most_common_word</th>\n",
       "      <th>3rd_most_common_word</th>\n",
       "      <th>4th_most_common_word</th>\n",
       "      <th>5th_most_common_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HTML</td>\n",
       "      <td>output githubdocument readmemd generated readm...</td>\n",
       "      <td>function lemur death age browser help causeofd...</td>\n",
       "      <td>life country using data expectancy file projec...</td>\n",
       "      <td>1221</td>\n",
       "      <td>612</td>\n",
       "      <td>55.5</td>\n",
       "      <td>30.5</td>\n",
       "      <td>life</td>\n",
       "      <td>expectancy</td>\n",
       "      <td>data</td>\n",
       "      <td>project</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Python</td>\n",
       "      <td>thoracic surgery lung cancer data set uci mach...</td>\n",
       "      <td>blood asthma pulmonary death powerpoint jupyte...</td>\n",
       "      <td>death jupyter age first research repository le...</td>\n",
       "      <td>8212</td>\n",
       "      <td>2273</td>\n",
       "      <td>122.6</td>\n",
       "      <td>28.0</td>\n",
       "      <td>life</td>\n",
       "      <td>expectancy</td>\n",
       "      <td>data</td>\n",
       "      <td>project</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R</td>\n",
       "      <td>reduction life expectancy brazil covid provide...</td>\n",
       "      <td>rsrio httpsdoiorgsz cassiomturrahttpstwitterco...</td>\n",
       "      <td>death age first method issue life among used i...</td>\n",
       "      <td>5467</td>\n",
       "      <td>1748</td>\n",
       "      <td>176.4</td>\n",
       "      <td>42.0</td>\n",
       "      <td>life</td>\n",
       "      <td>expectancy</td>\n",
       "      <td>data</td>\n",
       "      <td>r</td>\n",
       "      <td>year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>other</td>\n",
       "      <td>lifeexpectancy build statushttpstravisciorghem...</td>\n",
       "      <td>name code term rank principe stand higher requ...</td>\n",
       "      <td>name code license build lifeexpectancy type in...</td>\n",
       "      <td>4441</td>\n",
       "      <td>1638</td>\n",
       "      <td>96.5</td>\n",
       "      <td>16.5</td>\n",
       "      <td>life</td>\n",
       "      <td>expectancy</td>\n",
       "      <td>project</td>\n",
       "      <td>data</td>\n",
       "      <td>using</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                                          all_words  \\\n",
       "0     HTML  output githubdocument readmemd generated readm...   \n",
       "1   Python  thoracic surgery lung cancer data set uci mach...   \n",
       "2        R  reduction life expectancy brazil covid provide...   \n",
       "3    other  lifeexpectancy build statushttpstravisciorghem...   \n",
       "\n",
       "                                        unique_words  \\\n",
       "0  function lemur death age browser help causeofd...   \n",
       "1  blood asthma pulmonary death powerpoint jupyte...   \n",
       "2  rsrio httpsdoiorgsz cassiomturrahttpstwitterco...   \n",
       "3  name code term rank principe stand higher requ...   \n",
       "\n",
       "                                 common_unique_words  n_words  \\\n",
       "0  life country using data expectancy file projec...     1221   \n",
       "1  death jupyter age first research repository le...     8212   \n",
       "2  death age first method issue life among used i...     5467   \n",
       "3  name code license build lifeexpectancy type in...     4441   \n",
       "\n",
       "   unique_word_count  mean_word_count  median_word_count most_common_word  \\\n",
       "0                612             55.5               30.5             life   \n",
       "1               2273            122.6               28.0             life   \n",
       "2               1748            176.4               42.0             life   \n",
       "3               1638             96.5               16.5             life   \n",
       "\n",
       "  2nd_most_common_word 3rd_most_common_word 4th_most_common_word  \\\n",
       "0           expectancy                 data              project   \n",
       "1           expectancy                 data              project   \n",
       "2           expectancy                 data                    r   \n",
       "3           expectancy              project                 data   \n",
       "\n",
       "  5th_most_common_word  \n",
       "0              country  \n",
       "1              country  \n",
       "2                 year  \n",
       "3                using  "
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine all strings in more_clean where language is the same\n",
    "languages = df.groupby('language')['more_clean'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "languages.rename(columns={'more_clean':'all_words'}, inplace=True)\n",
    "languages['unique_words'] = df.groupby('language')['unique_words'].apply(lambda x: ' '.join(x)).values\n",
    "languages['common_unique_words'] = languages.unique_words.apply(get_common_unique_words)\n",
    "languages['n_words'] = languages['all_words'].apply(lambda x: len(x.split()))\n",
    "languages['unique_word_count'] = languages['all_words'].apply(lambda x: len(set(x.split())))\n",
    "languages['mean_word_count'] = df.groupby('language')['word_count'].mean().values.round(1)\n",
    "languages['median_word_count'] = df.groupby('language')['word_count'].median().values.round(1)\n",
    "languages['most_common_word'] = languages['unique_words'].apply(lambda x: prepare.n_most_common_word(x))\n",
    "languages['2nd_most_common_word'] = languages['unique_words'].apply(lambda x: prepare.n_most_common_word(x,2))\n",
    "languages['3rd_most_common_word'] = languages['unique_words'].apply(lambda x: prepare.n_most_common_word(x,3))\n",
    "languages['4th_most_common_word'] = languages['unique_words'].apply(lambda x: prepare.n_most_common_word(x,4))\n",
    "languages['5th_most_common_word'] = languages['unique_words'].apply(lambda x: prepare.n_most_common_word(x,5))\n",
    "languages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_set = set(languages[languages.language=='HTML'].common_unique_words.values[0].split())\n",
    "python_set = set(languages[languages.language=='Python'].common_unique_words.values[0].split())\n",
    "r_set = set(languages[languages.language=='R'].common_unique_words.values[0].split())\n",
    "other_set = set(languages[languages.language=='other'].common_unique_words.values[0].split())\n",
    "unique_to_html = html_set - python_set - r_set - other_set\n",
    "unique_to_python = python_set - html_set - r_set - other_set\n",
    "unique_to_r = r_set - html_set - python_set - other_set\n",
    "unique_to_other = other_set - html_set - python_set - r_set\n",
    "unique_to_lang = [unique_to_html, unique_to_python, unique_to_r, unique_to_other]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unique to lang is performed on full df but will be done on train then used for model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>all_words</th>\n",
       "      <th>unique_words</th>\n",
       "      <th>common_unique_words</th>\n",
       "      <th>n_words</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>mean_word_count</th>\n",
       "      <th>median_word_count</th>\n",
       "      <th>most_common_word</th>\n",
       "      <th>2nd_most_common_word</th>\n",
       "      <th>3rd_most_common_word</th>\n",
       "      <th>4th_most_common_word</th>\n",
       "      <th>5th_most_common_word</th>\n",
       "      <th>unique_to_language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HTML</td>\n",
       "      <td>output githubdocument readmemd generated readm...</td>\n",
       "      <td>function lemur death age browser help causeofd...</td>\n",
       "      <td>life country using data expectancy file projec...</td>\n",
       "      <td>1221</td>\n",
       "      <td>612</td>\n",
       "      <td>55.5</td>\n",
       "      <td>30.5</td>\n",
       "      <td>life</td>\n",
       "      <td>expectancy</td>\n",
       "      <td>data</td>\n",
       "      <td>project</td>\n",
       "      <td>country</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Python</td>\n",
       "      <td>thoracic surgery lung cancer data set uci mach...</td>\n",
       "      <td>blood asthma pulmonary death powerpoint jupyte...</td>\n",
       "      <td>death jupyter age first research repository le...</td>\n",
       "      <td>8212</td>\n",
       "      <td>2273</td>\n",
       "      <td>122.6</td>\n",
       "      <td>28.0</td>\n",
       "      <td>life</td>\n",
       "      <td>expectancy</td>\n",
       "      <td>data</td>\n",
       "      <td>project</td>\n",
       "      <td>country</td>\n",
       "      <td>{two, jupyter, matplotlib, current, link, miss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R</td>\n",
       "      <td>reduction life expectancy brazil covid provide...</td>\n",
       "      <td>rsrio httpsdoiorgsz cassiomturrahttpstwitterco...</td>\n",
       "      <td>death age first method issue life among used i...</td>\n",
       "      <td>5467</td>\n",
       "      <td>1748</td>\n",
       "      <td>176.4</td>\n",
       "      <td>42.0</td>\n",
       "      <td>life</td>\n",
       "      <td>expectancy</td>\n",
       "      <td>data</td>\n",
       "      <td>r</td>\n",
       "      <td>year</td>\n",
       "      <td>{r, includes, paper, calculate, function, issu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>other</td>\n",
       "      <td>lifeexpectancy build statushttpstravisciorghem...</td>\n",
       "      <td>name code term rank principe stand higher requ...</td>\n",
       "      <td>name code license build lifeexpectancy type in...</td>\n",
       "      <td>4441</td>\n",
       "      <td>1638</td>\n",
       "      <td>96.5</td>\n",
       "      <td>16.5</td>\n",
       "      <td>life</td>\n",
       "      <td>expectancy</td>\n",
       "      <td>project</td>\n",
       "      <td>data</td>\n",
       "      <td>using</td>\n",
       "      <td>{running, day, user, instruction, license, dir...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                                          all_words  \\\n",
       "0     HTML  output githubdocument readmemd generated readm...   \n",
       "1   Python  thoracic surgery lung cancer data set uci mach...   \n",
       "2        R  reduction life expectancy brazil covid provide...   \n",
       "3    other  lifeexpectancy build statushttpstravisciorghem...   \n",
       "\n",
       "                                        unique_words  \\\n",
       "0  function lemur death age browser help causeofd...   \n",
       "1  blood asthma pulmonary death powerpoint jupyte...   \n",
       "2  rsrio httpsdoiorgsz cassiomturrahttpstwitterco...   \n",
       "3  name code term rank principe stand higher requ...   \n",
       "\n",
       "                                 common_unique_words  n_words  \\\n",
       "0  life country using data expectancy file projec...     1221   \n",
       "1  death jupyter age first research repository le...     8212   \n",
       "2  death age first method issue life among used i...     5467   \n",
       "3  name code license build lifeexpectancy type in...     4441   \n",
       "\n",
       "   unique_word_count  mean_word_count  median_word_count most_common_word  \\\n",
       "0                612             55.5               30.5             life   \n",
       "1               2273            122.6               28.0             life   \n",
       "2               1748            176.4               42.0             life   \n",
       "3               1638             96.5               16.5             life   \n",
       "\n",
       "  2nd_most_common_word 3rd_most_common_word 4th_most_common_word  \\\n",
       "0           expectancy                 data              project   \n",
       "1           expectancy                 data              project   \n",
       "2           expectancy                 data                    r   \n",
       "3           expectancy              project                 data   \n",
       "\n",
       "  5th_most_common_word                                 unique_to_language  \n",
       "0              country                                                 {}  \n",
       "1              country  {two, jupyter, matplotlib, current, link, miss...  \n",
       "2                 year  {r, includes, paper, calculate, function, issu...  \n",
       "3                using  {running, day, user, instruction, license, dir...  "
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages['unique_to_language'] = unique_to_lang\n",
    "languages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('life', 19),\n",
       " ('expectancy', 19),\n",
       " ('data', 10),\n",
       " ('project', 10),\n",
       " ('country', 9)]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = Counter(languages[languages.language=='HTML'].unique_words.str.split()[0]).most_common(5)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'isin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/f5/w0p7b4_j2kdg3kvlsz7nhtn40000gn/T/ipykernel_52565/2238514997.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlanguages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlanguages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'HTML'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlanguages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'R'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'isin'"
     ]
    }
   ],
   "source": [
    "languages[languages.language=='HTML'].unique_words.str.split()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
