{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import unicodedata\n",
    "import re\n",
    "import env\n",
    "import prepare\n",
    "from matplotlib import style\n",
    "style.use(\"ggplot\")\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mcastrolab/Brazil-Covid19-e0-change</td>\n",
       "      <td>R</td>\n",
       "      <td># Reduction in life expectancy in Brazil after...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jschoeley/de0anim</td>\n",
       "      <td>R</td>\n",
       "      <td># Animated annual changes in life-expectancy\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sychi77/Thoracic_Surgery_Patient_Survival</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td># Thoracic Surgery for Lung Cancer Data Set\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ashtad63/HackerRank-Data-Scientist-Hiring-Test</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td># HackerRank Data Scientist Hiring Test: Predi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OxfordDemSci/ex2020</td>\n",
       "      <td>R</td>\n",
       "      <td>&lt;p align=\"center\"&gt;\\n  &lt;img src=\"https://github...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             repo          language  \\\n",
       "0             mcastrolab/Brazil-Covid19-e0-change                 R   \n",
       "1                               jschoeley/de0anim                 R   \n",
       "2       sychi77/Thoracic_Surgery_Patient_Survival  Jupyter Notebook   \n",
       "3  ashtad63/HackerRank-Data-Scientist-Hiring-Test  Jupyter Notebook   \n",
       "4                             OxfordDemSci/ex2020                 R   \n",
       "\n",
       "                                     readme_contents  \n",
       "0  # Reduction in life expectancy in Brazil after...  \n",
       "1  # Animated annual changes in life-expectancy\\n...  \n",
       "2  # Thoracic Surgery for Lung Cancer Data Set\\n ...  \n",
       "3  # HackerRank Data Scientist Hiring Test: Predi...  \n",
       "4  <p align=\"center\">\\n  <img src=\"https://github...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make df from data.json\n",
    "df = pd.read_json('data.json')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Jupyter Notebook    10\n",
       "R                    5\n",
       "Stata                3\n",
       "HTML                 2\n",
       "Python               1\n",
       "Objective-C          1\n",
       "Scheme               1\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many rows  have readme_contents with length == 0\n",
    "df[df['readme_contents'].str.len() == 0].language.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language\n",
       "Objective-C         1.000000\n",
       "Scheme              1.000000\n",
       "Stata               0.600000\n",
       "Jupyter Notebook    0.208333\n",
       "R                   0.161290\n",
       "HTML                0.090909\n",
       "Python              0.052632\n",
       "Dart                0.000000\n",
       "Java                0.000000\n",
       "JavaScript          0.000000\n",
       "MATLAB              0.000000\n",
       "Ruby                0.000000\n",
       "Scala               0.000000\n",
       "Shell               0.000000\n",
       "Swift               0.000000\n",
       "TypeScript          0.000000\n",
       "Name: no_readme_contents, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"no_readme_contents\"] = df[\"readme_contents\"].str.len()==0\n",
    "# person of language with no readme_contents\n",
    "df.groupby(\"language\")[\"no_readme_contents\"].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Jupyter Notebook    48\n",
       "R                   31\n",
       "HTML                22\n",
       "Python              19\n",
       "JavaScript          16\n",
       "Stata                5\n",
       "Java                 3\n",
       "Dart                 3\n",
       "Scala                2\n",
       "Swift                2\n",
       "MATLAB               1\n",
       "Shell                1\n",
       "TypeScript           1\n",
       "Ruby                 1\n",
       "Objective-C          1\n",
       "Scheme               1\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many languages are there?\n",
    "df['language'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= prepare.prep_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language\n",
       "HTML      0.0\n",
       "Other     0.0\n",
       "Python    0.0\n",
       "R         0.0\n",
       "Name: no_readme_contents, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"no_readme_contents\"] = df[\"more_clean\"].str.len()==0\n",
    "\n",
    "# person of language with no readme_contents\n",
    "df.groupby(\"language\")[\"no_readme_contents\"].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many rows do we have\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many rows are missing readme data\n",
    "df[df.no_readme_contents==True].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: language, dtype: int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.no_readme_contents==True].language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>original</th>\n",
       "      <th>no_readme_contents</th>\n",
       "      <th>more_clean</th>\n",
       "      <th>unique_words</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>most_common_word</th>\n",
       "      <th>2nd_most_common_word</th>\n",
       "      <th>3rd_most_common_word</th>\n",
       "      <th>4th_most_common_word</th>\n",
       "      <th>5th_most_common_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mcastrolab/Brazil-Covid19-e0-change</td>\n",
       "      <td>R</td>\n",
       "      <td># Reduction in life expectancy in Brazil after...</td>\n",
       "      <td>False</td>\n",
       "      <td>reduction life expectancy brazil covid provide...</td>\n",
       "      <td>seen reduced al based first code publication i...</td>\n",
       "      <td>2949</td>\n",
       "      <td>352</td>\n",
       "      <td>211</td>\n",
       "      <td>life</td>\n",
       "      <td>expectancy</td>\n",
       "      <td>covid</td>\n",
       "      <td>state</td>\n",
       "      <td>data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jschoeley/de0anim</td>\n",
       "      <td>R</td>\n",
       "      <td># Animated annual changes in life-expectancy\\n...</td>\n",
       "      <td>False</td>\n",
       "      <td>animated annual change lifeexpectancy illustra...</td>\n",
       "      <td>losseshttpsgithubcomoxforddemsciex lifeexpecta...</td>\n",
       "      <td>166</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>animated</td>\n",
       "      <td>annual</td>\n",
       "      <td>change</td>\n",
       "      <td>lifeexpectancy</td>\n",
       "      <td>illustration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sychi77/Thoracic_Surgery_Patient_Survival</td>\n",
       "      <td>Python</td>\n",
       "      <td># Thoracic Surgery for Lung Cancer Data Set\\n ...</td>\n",
       "      <td>False</td>\n",
       "      <td>thoracic surgery lung cancer data set uci mach...</td>\n",
       "      <td>code first institute tnm one lung registry siz...</td>\n",
       "      <td>2058</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>surgery</td>\n",
       "      <td>f</td>\n",
       "      <td>data</td>\n",
       "      <td>lung</td>\n",
       "      <td>thoracic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ashtad63/HackerRank-Data-Scientist-Hiring-Test</td>\n",
       "      <td>Python</td>\n",
       "      <td># HackerRank Data Scientist Hiring Test: Predi...</td>\n",
       "      <td>False</td>\n",
       "      <td>hackerrank data scientist hiring test predict ...</td>\n",
       "      <td>first institute prediction united test organiz...</td>\n",
       "      <td>1011</td>\n",
       "      <td>135</td>\n",
       "      <td>86</td>\n",
       "      <td>country</td>\n",
       "      <td>life</td>\n",
       "      <td>expectancy</td>\n",
       "      <td>must</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OxfordDemSci/ex2020</td>\n",
       "      <td>R</td>\n",
       "      <td>&lt;p align=\"center\"&gt;\\n  &lt;img src=\"https://github...</td>\n",
       "      <td>False</td>\n",
       "      <td>p aligncenter img srchttpsgithubcomoxforddemsc...</td>\n",
       "      <td>functionality code ie sequential issue underta...</td>\n",
       "      <td>2259</td>\n",
       "      <td>234</td>\n",
       "      <td>172</td>\n",
       "      <td>data</td>\n",
       "      <td>relates</td>\n",
       "      <td>code</td>\n",
       "      <td>p</td>\n",
       "      <td>generic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             repo language  \\\n",
       "0             mcastrolab/Brazil-Covid19-e0-change        R   \n",
       "1                               jschoeley/de0anim        R   \n",
       "2       sychi77/Thoracic_Surgery_Patient_Survival   Python   \n",
       "3  ashtad63/HackerRank-Data-Scientist-Hiring-Test   Python   \n",
       "4                             OxfordDemSci/ex2020        R   \n",
       "\n",
       "                                            original  no_readme_contents  \\\n",
       "0  # Reduction in life expectancy in Brazil after...               False   \n",
       "1  # Animated annual changes in life-expectancy\\n...               False   \n",
       "2  # Thoracic Surgery for Lung Cancer Data Set\\n ...               False   \n",
       "3  # HackerRank Data Scientist Hiring Test: Predi...               False   \n",
       "4  <p align=\"center\">\\n  <img src=\"https://github...               False   \n",
       "\n",
       "                                          more_clean  \\\n",
       "0  reduction life expectancy brazil covid provide...   \n",
       "1  animated annual change lifeexpectancy illustra...   \n",
       "2  thoracic surgery lung cancer data set uci mach...   \n",
       "3  hackerrank data scientist hiring test predict ...   \n",
       "4  p aligncenter img srchttpsgithubcomoxforddemsc...   \n",
       "\n",
       "                                        unique_words  char_count  word_count  \\\n",
       "0  seen reduced al based first code publication i...        2949         352   \n",
       "1  losseshttpsgithubcomoxforddemsciex lifeexpecta...         166          16   \n",
       "2  code first institute tnm one lung registry siz...        2058         234   \n",
       "3  first institute prediction united test organiz...        1011         135   \n",
       "4  functionality code ie sequential issue underta...        2259         234   \n",
       "\n",
       "   unique_word_count most_common_word 2nd_most_common_word  \\\n",
       "0                211             life           expectancy   \n",
       "1                 16         animated               annual   \n",
       "2                150          surgery                    f   \n",
       "3                 86          country                 life   \n",
       "4                172             data              relates   \n",
       "\n",
       "  3rd_most_common_word 4th_most_common_word 5th_most_common_word  \n",
       "0                covid                state                 data  \n",
       "1               change       lifeexpectancy         illustration  \n",
       "2                 data                 lung             thoracic  \n",
       "3           expectancy                 must                 test  \n",
       "4                 code                    p              generic  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Python    56\n",
       "Other     32\n",
       "R         26\n",
       "HTML      20\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many languages are there?\n",
    "df['language'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make vectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "# fit the vectorizer to the data and make df\n",
    "X = tfidf.fit_transform(df['more_clean'])\n",
    "y = df['language']\n",
    "\n",
    "# split data into train and test\n",
    "X_train, X_validate, X_test, y_train, y_validate, y_test = prepare.split_data_xy(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_accuracy(df, mode):\n",
    "    \"\"\"\n",
    "    Calculate baseline accuracy\n",
    "    \"\"\"\n",
    "    df['mode'] = mode\n",
    "    baseline_accuracy = accuracy_score(df['actual'], df['mode'])\n",
    "    return baseline_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get mode to use as baseline\n",
    "mode = df.language.mode().values[0]\n",
    "#get baseline_accuracy\n",
    "train_baseline = baseline_accuracy(train, mode)\n",
    "validate_baseline = baseline_accuracy(validate, mode)\n",
    "test_baseline = baseline_accuracy(test, mode)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_number</th>\n",
       "      <th>model_type</th>\n",
       "      <th>solver</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>better_than_baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.418919</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_number model_type solver train_accuracy validate_accuracy  \\\n",
       "0     baseline   baseline    NaN       0.418919          0.424242   \n",
       "\n",
       "  test_accuracy better_than_baseline  \n",
       "0      0.407407                False  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a df for results\n",
    "results = pd.DataFrame()\n",
    "baseline_model = pd.Series({'model_number':'baseline','model_type':'baseline','solver':np.nan,'train_accuracy':train_baseline,'validate_accuracy':validate_baseline,'test_accuracy':test_baseline, 'better_than_baseline':False})\n",
    "results = pd.concat([results, baseline_model],axis = 0)\n",
    "results.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_number</th>\n",
       "      <th>model_type</th>\n",
       "      <th>solver</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>better_than_baseline</th>\n",
       "      <th>include_jupyter_notebook</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.418919</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.851351</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.851351</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.851351</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_number          model_type     solver train_accuracy  \\\n",
       "0     baseline            baseline        NaN       0.418919   \n",
       "1            1  LogisticRegression  liblinear       0.783784   \n",
       "2            2  LogisticRegression      lbfgs       0.851351   \n",
       "3            3  LogisticRegression  newton-cg       0.851351   \n",
       "4            4  LogisticRegression        sag       0.851351   \n",
       "5            5  LogisticRegression       saga       0.891892   \n",
       "\n",
       "  validate_accuracy test_accuracy better_than_baseline  \\\n",
       "0          0.424242      0.407407                False   \n",
       "1          0.424242      0.444444                False   \n",
       "2          0.424242      0.444444                False   \n",
       "3          0.424242      0.444444                False   \n",
       "4          0.424242      0.444444                False   \n",
       "5          0.424242      0.444444                False   \n",
       "\n",
       "  include_jupyter_notebook  \n",
       "0                      NaN  \n",
       "1                    False  \n",
       "2                    False  \n",
       "3                    False  \n",
       "4                    False  \n",
       "5                    False  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a df for results\n",
    "results = pd.DataFrame()\n",
    "baseline_model = pd.Series({'model_number':'baseline','model_type':'baseline','solver':np.nan,'train_accuracy':train_baseline,'validate_accuracy':validate_baseline,'test_accuracy':test_baseline, 'better_than_baseline':False})\n",
    "results = pd.concat([results, baseline_model],axis = 0)\n",
    "results.T\n",
    "# make more models varying solver\n",
    "model_number = results.shape[1]\n",
    "for solver in ['liblinear','lbfgs','newton-cg','sag','saga']:\n",
    "    lm = LogisticRegression(solver=solver).fit(X_train, y_train)\n",
    "    # run model on data splits\n",
    "    train['predicted'] = lm.predict(X_train)\n",
    "    validate['predicted'] = lm.predict(X_validate)\n",
    "    test['predicted'] = lm.predict(X_test)\n",
    "    # make results series to add to results df\n",
    "    stats = pd.Series(\n",
    "        {'model_number':model_number,\n",
    "            'model_type':'LogisticRegression',\n",
    "            'solver':solver,\n",
    "            'train_accuracy':accuracy_score(y_train, train['predicted']),\n",
    "            'validate_accuracy':accuracy_score(y_validate, validate['predicted']),\n",
    "            'test_accuracy':accuracy_score(y_test, test['predicted']),\n",
    "            'better_than_baseline':accuracy_score(y_validate, validate['predicted'])>validate_baseline,\n",
    "            'include_jupyter_notebook':'Jupyter Notebook' in df.language\n",
    "        })\n",
    "    # add to results df\n",
    "    results = pd.concat([results, stats], axis = 1)\n",
    "    model_number += 1\n",
    "\n",
    "results.T.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_low_count_languages(df, threshold=3):\n",
    "    \"\"\"\n",
    "    Drop languages with less than threshold number of entries\n",
    "    \"\"\"\n",
    "    languages = (df['language'].value_counts()>3)\n",
    "    to_keep = languages[languages==True].index.tolist()\n",
    "    df = df[df['language'].isin(to_keep)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<134x4418 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 10335 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "# fit the vectorizer to the data and make df\n",
    "X = tfidf.fit_transform(df['more_clean'])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models(drop_jupyter=True, drop_low_count_langs=True, n_languages=3):\n",
    "    \"\"\"\n",
    "    Run models on data varying solver\n",
    "    \"\"\"\n",
    "    #get raw data\n",
    "    df = pd.read_json('data.json')\n",
    "    # clean data\n",
    "    df['more_clean'] = df['readme_contents'].apply(prepare.more_clean)\n",
    "    if drop_jupyter:\n",
    "        df = df[df['language'] != 'Jupyter Notebook']\n",
    "    if drop_low_count_langs:\n",
    "        df = drop_low_count_languages(df)\n",
    "    df = prepare.keep_top_n_languages(df, n_languages=n_languages)\n",
    "    # make vectorizer\n",
    "    tfidf = TfidfVectorizer()\n",
    "    # fit the vectorizer to the data and make df\n",
    "    X = tfidf.fit_transform(df['more_clean'])\n",
    "    y = df['language']\n",
    "\n",
    "    # split data into train and test\n",
    "    X_train, X_validate, X_test, y_train, y_validate, y_test = prepare.split_data_xy(X, y)\n",
    "    train = pd.DataFrame(dict(actual=y_train))\n",
    "    validate = pd.DataFrame(dict(actual=y_validate))\n",
    "    test = pd.DataFrame(dict(actual=y_test))\n",
    "    #get mode to use as baseline\n",
    "    mode = df.language.mode().values[0]\n",
    "    #get baseline_accuracy\n",
    "    train_baseline = baseline_accuracy(train, mode)\n",
    "    validate_baseline = baseline_accuracy(validate, mode)\n",
    "    test_baseline = baseline_accuracy(test, mode)\n",
    "    # make a df for results\n",
    "    results = pd.DataFrame()\n",
    "    # make baseline model\n",
    "    baseline_model = pd.Series({'model_number':'baseline','model_type':'baseline','solver':np.nan,'train_accuracy':train_baseline,'validate_accuracy':validate_baseline,'test_accuracy':test_baseline, 'better_than_baseline':False})\n",
    "    # add baseline model to results df\n",
    "    results = pd.concat([results, baseline_model],axis = 0)\n",
    "    # make more models varying solver\n",
    "    model_number = results.shape[1]\n",
    "    for solver in ['liblinear','lbfgs','newton-cg','sag','saga']:\n",
    "        lm = LogisticRegression(solver=solver).fit(X_train, y_train)\n",
    "        # run model on data splits\n",
    "        train['predicted'] = lm.predict(X_train)\n",
    "        validate['predicted'] = lm.predict(X_validate)\n",
    "        test['predicted'] = lm.predict(X_test)\n",
    "        # make results series to add to results df\n",
    "        stats = pd.Series(\n",
    "        {'model_number':model_number,\n",
    "            'model_type':'LogisticRegression',\n",
    "            'solver':solver,\n",
    "            'train_accuracy':accuracy_score(y_train, train['predicted']),\n",
    "            'validate_accuracy':accuracy_score(y_validate, validate['predicted']),\n",
    "            'test_accuracy':accuracy_score(y_test, test['predicted']),\n",
    "            'better_than_baseline':accuracy_score(y_validate, validate['predicted'])>validate_baseline,\n",
    "            'drop_jupyter':drop_jupyter,\n",
    "            'drop_low_count_languages':drop_low_count_langs,\n",
    "            'n_languages':n_languages\n",
    "        })\n",
    "        # add to results df\n",
    "        results = pd.concat([results, stats], axis = 1)\n",
    "        model_number += 1\n",
    "\n",
    "    return results.T.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_number</th>\n",
       "      <th>model_type</th>\n",
       "      <th>solver</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>better_than_baseline</th>\n",
       "      <th>drop_jupyter</th>\n",
       "      <th>drop_low_count_languages</th>\n",
       "      <th>n_languages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_number          model_type     solver train_accuracy  \\\n",
       "0     baseline            baseline        NaN       0.333333   \n",
       "1            1  LogisticRegression  liblinear       0.882353   \n",
       "2            2  LogisticRegression      lbfgs       0.901961   \n",
       "3            3  LogisticRegression  newton-cg       0.901961   \n",
       "4            4  LogisticRegression        sag       0.901961   \n",
       "5            5  LogisticRegression       saga       0.901961   \n",
       "\n",
       "  validate_accuracy test_accuracy better_than_baseline drop_jupyter  \\\n",
       "0          0.347826      0.315789                False          NaN   \n",
       "1          0.347826      0.368421                False         True   \n",
       "2          0.347826      0.368421                False         True   \n",
       "3          0.347826      0.368421                False         True   \n",
       "4          0.347826      0.368421                False         True   \n",
       "5          0.347826      0.421053                False         True   \n",
       "\n",
       "  drop_low_count_languages n_languages  \n",
       "0                      NaN         NaN  \n",
       "1                     True           3  \n",
       "2                     True           3  \n",
       "3                     True           3  \n",
       "4                     True           3  \n",
       "5                     True           3  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_models(drop_jupyter=True, drop_low_count_langs=True, n_languages=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_number</th>\n",
       "      <th>model_type</th>\n",
       "      <th>solver</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>better_than_baseline</th>\n",
       "      <th>drop_jupyter</th>\n",
       "      <th>drop_low_count_languages</th>\n",
       "      <th>n_languages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.37931</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.37931</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.37931</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_number          model_type     solver train_accuracy  \\\n",
       "0     baseline            baseline        NaN       0.346154   \n",
       "1            1  LogisticRegression  liblinear       0.871795   \n",
       "2            2  LogisticRegression      lbfgs       0.923077   \n",
       "3            3  LogisticRegression  newton-cg       0.923077   \n",
       "4            4  LogisticRegression        sag       0.923077   \n",
       "5            5  LogisticRegression       saga       0.923077   \n",
       "\n",
       "  validate_accuracy test_accuracy better_than_baseline drop_jupyter  \\\n",
       "0          0.323529      0.344828                False          NaN   \n",
       "1          0.382353      0.344828                 True        False   \n",
       "2          0.382353       0.37931                 True        False   \n",
       "3          0.382353       0.37931                 True        False   \n",
       "4          0.382353       0.37931                 True        False   \n",
       "5          0.382353      0.344828                 True        False   \n",
       "\n",
       "  drop_low_count_languages n_languages  \n",
       "0                      NaN         NaN  \n",
       "1                     True           3  \n",
       "2                     True           3  \n",
       "3                     True           3  \n",
       "4                     True           3  \n",
       "5                     True           3  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_models(drop_jupyter=False, drop_low_count_langs=True, n_languages=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_number</th>\n",
       "      <th>model_type</th>\n",
       "      <th>solver</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>better_than_baseline</th>\n",
       "      <th>drop_jupyter</th>\n",
       "      <th>drop_low_count_languages</th>\n",
       "      <th>n_languages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>sag</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.793478</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_number          model_type     solver train_accuracy  \\\n",
       "0     baseline            baseline        NaN       0.391304   \n",
       "1            1  LogisticRegression  liblinear       0.695652   \n",
       "2            2  LogisticRegression      lbfgs       0.782609   \n",
       "3            3  LogisticRegression  newton-cg       0.782609   \n",
       "4            4  LogisticRegression        sag       0.782609   \n",
       "5            5  LogisticRegression       saga       0.793478   \n",
       "\n",
       "  validate_accuracy test_accuracy better_than_baseline drop_jupyter  \\\n",
       "0               0.4      0.382353                False          NaN   \n",
       "1               0.5      0.411765                 True        False   \n",
       "2             0.525      0.441176                 True        False   \n",
       "3             0.525      0.441176                 True        False   \n",
       "4             0.525      0.441176                 True        False   \n",
       "5             0.525      0.441176                 True        False   \n",
       "\n",
       "  drop_low_count_languages n_languages  \n",
       "0                      NaN         NaN  \n",
       "1                    False           3  \n",
       "2                    False           3  \n",
       "3                    False           3  \n",
       "4                    False           3  \n",
       "5                    False           3  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_models(drop_jupyter=False, drop_low_count_langs=False, n_languages=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models2(drop_jupyter=True, drop_low_count_langs=True, drop_empty_readmes=True, n_languages=3):\n",
    "    \"\"\"\n",
    "    Run models on data varying solver and C value\n",
    "    \"\"\"\n",
    "    #get raw data\n",
    "    df = pd.read_json('data.json')\n",
    "    # clean data\n",
    "    df['more_clean'] = df['readme_contents'].apply(prepare.more_clean)\n",
    "    if drop_jupyter:\n",
    "        df = df[df['language'] != 'Jupyter Notebook']\n",
    "    if drop_low_count_langs:\n",
    "        df = drop_low_count_languages(df)\n",
    "    if drop_empty_readmes:\n",
    "        df = df[df['more_clean'] != '']\n",
    "    df = prepare.keep_top_n_languages(df, n_languages=n_languages)\n",
    "    # make vectorizer\n",
    "    tfidf = TfidfVectorizer()\n",
    "    # fit the vectorizer to the data and make df\n",
    "    X = tfidf.fit_transform(df['more_clean'])\n",
    "    y = df['language']\n",
    "\n",
    "    # split data into train and test\n",
    "    X_train, X_validate, X_test, y_train, y_validate, y_test = prepare.split_data_xy(X, y)\n",
    "    train = pd.DataFrame(dict(actual=y_train))\n",
    "    validate = pd.DataFrame(dict(actual=y_validate))\n",
    "    test = pd.DataFrame(dict(actual=y_test))\n",
    "    #get mode to use as baseline\n",
    "    mode = df.language.mode().values[0]\n",
    "    #get baseline_accuracy\n",
    "    train_baseline = baseline_accuracy(train, mode)\n",
    "    validate_baseline = baseline_accuracy(validate, mode)\n",
    "    test_baseline = baseline_accuracy(test, mode)\n",
    "    # make a df for results\n",
    "    results = pd.DataFrame()\n",
    "    # make baseline model\n",
    "    baseline_model = pd.Series({'model_number':'baseline','model_type':'baseline','solver':np.nan,'train_accuracy':train_baseline,'validate_accuracy':validate_baseline,'test_accuracy':test_baseline, 'better_than_baseline':False})\n",
    "    # add baseline model to results df\n",
    "    results = pd.concat([results, baseline_model],axis = 0)\n",
    "    # make more models varying solver\n",
    "    model_number = results.shape[1]\n",
    "    c_values = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "    for solver in ['liblinear','lbfgs','newton-cg','sag','saga']:\n",
    "        for c in c_values:\n",
    "            #make the model\n",
    "            lm = LogisticRegression(C=c, solver=solver).fit(X_train, y_train)\n",
    "            # run model on data splits\n",
    "            train['predicted'] = lm.predict(X_train)\n",
    "            validate['predicted'] = lm.predict(X_validate)\n",
    "            test['predicted'] = lm.predict(X_test)\n",
    "            # make results series to add to results df\n",
    "            stats = pd.Series(\n",
    "            {'model_number':model_number,\n",
    "                'model_type':'LogisticRegression',\n",
    "                'solver':solver,\n",
    "                'C':c,\n",
    "                'train_accuracy':accuracy_score(y_train, train['predicted']),\n",
    "                'validate_accuracy':accuracy_score(y_validate, validate['predicted']),\n",
    "                'test_accuracy':accuracy_score(y_test, test['predicted']),\n",
    "                'better_than_baseline':accuracy_score(y_validate, validate['predicted'])>validate_baseline,\n",
    "                'drop_jupyter':drop_jupyter,\n",
    "                'drop_low_count_languages':drop_low_count_langs,\n",
    "                'drop_empty_readmes':drop_empty_readmes,\n",
    "                'n_languages':n_languages\n",
    "            })\n",
    "            # add to results df\n",
    "            results = pd.concat([results, stats], axis = 1)\n",
    "            model_number += 1\n",
    "\n",
    "    return results.T.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_number</th>\n",
       "      <th>model_type</th>\n",
       "      <th>solver</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>better_than_baseline</th>\n",
       "      <th>C</th>\n",
       "      <th>drop_jupyter</th>\n",
       "      <th>drop_low_count_languages</th>\n",
       "      <th>drop_empty_readmes</th>\n",
       "      <th>n_languages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>sag</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>True</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>True</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>True</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_number          model_type     solver train_accuracy  \\\n",
       "28           28  LogisticRegression        sag            1.0   \n",
       "7             7  LogisticRegression  liblinear            1.0   \n",
       "21           21  LogisticRegression  newton-cg            1.0   \n",
       "\n",
       "   validate_accuracy test_accuracy better_than_baseline     C drop_jupyter  \\\n",
       "28               0.7      0.352941                 True  1000         True   \n",
       "7                0.7      0.470588                 True  1000         True   \n",
       "21               0.7      0.411765                 True  1000         True   \n",
       "\n",
       "   drop_low_count_languages drop_empty_readmes n_languages  \n",
       "28                     True               True           3  \n",
       "7                      True               True           3  \n",
       "21                     True               True           3  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_models2(drop_jupyter=True, drop_low_count_langs=True, n_languages=3).sort_values('validate_accuracy', ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_number</th>\n",
       "      <th>model_type</th>\n",
       "      <th>solver</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>better_than_baseline</th>\n",
       "      <th>C</th>\n",
       "      <th>drop_jupyter</th>\n",
       "      <th>drop_low_count_languages</th>\n",
       "      <th>drop_empty_readmes</th>\n",
       "      <th>n_languages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>saga</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>sag</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.625</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_number          model_type     solver train_accuracy  \\\n",
       "33           33  LogisticRegression       saga            1.0   \n",
       "5             5  LogisticRegression  liblinear            1.0   \n",
       "26           26  LogisticRegression        sag            1.0   \n",
       "\n",
       "   validate_accuracy test_accuracy better_than_baseline   C drop_jupyter  \\\n",
       "33          0.551724      0.541667                 True  10        False   \n",
       "5           0.551724      0.583333                 True  10        False   \n",
       "26          0.551724         0.625                 True  10        False   \n",
       "\n",
       "   drop_low_count_languages drop_empty_readmes n_languages  \n",
       "33                     True               True           3  \n",
       "5                      True               True           3  \n",
       "26                     True               True           3  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_models2(drop_jupyter=False, drop_low_count_langs=True, n_languages=3).sort_values('validate_accuracy', ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_number</th>\n",
       "      <th>model_type</th>\n",
       "      <th>solver</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>better_than_baseline</th>\n",
       "      <th>C</th>\n",
       "      <th>drop_jupyter</th>\n",
       "      <th>drop_low_count_languages</th>\n",
       "      <th>drop_empty_readmes</th>\n",
       "      <th>n_languages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.397436</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.397436</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.910256</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_number          model_type     solver train_accuracy  \\\n",
       "0      baseline            baseline        NaN       0.397436   \n",
       "15           15  LogisticRegression  newton-cg       0.397436   \n",
       "32           32  LogisticRegression       saga       0.910256   \n",
       "\n",
       "   validate_accuracy test_accuracy better_than_baseline      C drop_jupyter  \\\n",
       "0           0.411765      0.392857                False    NaN          NaN   \n",
       "15          0.411765      0.392857                False  0.001        False   \n",
       "32          0.411765      0.571429                False      1        False   \n",
       "\n",
       "   drop_low_count_languages drop_empty_readmes n_languages  \n",
       "0                       NaN                NaN         NaN  \n",
       "15                    False               True           3  \n",
       "32                    False               True           3  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_models2(drop_jupyter=False, drop_low_count_langs=False, n_languages=3).sort_values('validate_accuracy', ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_number</th>\n",
       "      <th>model_type</th>\n",
       "      <th>solver</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>better_than_baseline</th>\n",
       "      <th>C</th>\n",
       "      <th>drop_jupyter</th>\n",
       "      <th>drop_low_count_languages</th>\n",
       "      <th>drop_empty_readmes</th>\n",
       "      <th>n_languages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_number          model_type     solver train_accuracy  \\\n",
       "5             5  LogisticRegression  liblinear            1.0   \n",
       "11           11  LogisticRegression      lbfgs       0.897436   \n",
       "12           12  LogisticRegression      lbfgs            1.0   \n",
       "\n",
       "   validate_accuracy test_accuracy better_than_baseline   C drop_jupyter  \\\n",
       "5           0.411765      0.571429                False  10        False   \n",
       "11          0.411765      0.571429                False   1        False   \n",
       "12          0.411765      0.571429                False  10        False   \n",
       "\n",
       "   drop_low_count_languages drop_empty_readmes n_languages  \n",
       "5                     False               True           3  \n",
       "11                    False               True           3  \n",
       "12                    False               True           3  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_models2(drop_jupyter=False, drop_low_count_langs=False, drop_empty_readmes=True, n_languages=3).sort_values(['validate_accuracy','test_accuracy'], ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moved to prepare.py\n",
    "# \n",
    "# # which word is the most common in the string\n",
    "# def n_most_common_word(string, n=1):\n",
    "#     \"\"\"\n",
    "#     Return the most common word in a string\n",
    "#     \"\"\"\n",
    "#     words = string.split()\n",
    "#     if len(words) < n:\n",
    "#         return ''\n",
    "#     word_counts = Counter(words)\n",
    "#     return word_counts.most_common(n)[n-1][0]\n",
    "\n",
    "# n_most_common_word(df.more_clean[1],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models3():\n",
    "    \"\"\"\n",
    "    Run models with decision tree classifier\n",
    "    \"\"\"\n",
    "    #get raw data\n",
    "    df = pd.read_json('data.json')\n",
    "    df = prepare.prep_data(df)\n",
    "    # make vectorizer\n",
    "    tfidf = TfidfVectorizer()\n",
    "    # fit the vectorizer to the data and make df\n",
    "    X = tfidf.fit_transform(df['more_clean'])\n",
    "    y = df['language']\n",
    "\n",
    "    # split data into train and test\n",
    "    X_train, X_validate, X_test, y_train, y_validate, y_test = prepare.split_data_xy(X, y)\n",
    "    train = pd.DataFrame(dict(actual=y_train))\n",
    "    validate = pd.DataFrame(dict(actual=y_validate))\n",
    "    test = pd.DataFrame(dict(actual=y_test))\n",
    "    #get mode to use as baseline\n",
    "    mode = df.language.mode().values[0]\n",
    "    #get baseline_accuracy\n",
    "    train_baseline = baseline_accuracy(train, mode)\n",
    "    validate_baseline = baseline_accuracy(validate, mode)\n",
    "    test_baseline = baseline_accuracy(test, mode)\n",
    "    # make a df for results\n",
    "    results = pd.DataFrame()\n",
    "    # make baseline model\n",
    "    baseline_model = pd.Series({'model_number':'baseline','model_type':'baseline','solver':np.nan,'train_accuracy':train_baseline,'validate_accuracy':validate_baseline,'test_accuracy':test_baseline, 'better_than_baseline':False})\n",
    "    # add baseline model to results df\n",
    "    results = pd.concat([results, baseline_model],axis = 0)\n",
    "    # make more models varying solver\n",
    "    model_number = results.shape[1]\n",
    "    max_depths = [1, 2, 3, 4, 5, 10, 100]\n",
    "    for max_depth in max_depths:\n",
    "        #make the model\n",
    "        dtc = DecisionTreeClassifier(max_depth=max_depth, random_state=42).fit(X_train, y_train)\n",
    "        # run model on data splits\n",
    "        train['predicted'] = dtc.predict(X_train)\n",
    "        validate['predicted'] = dtc.predict(X_validate)\n",
    "        test['predicted'] = dtc.predict(X_test)\n",
    "        # make results series to add to results df\n",
    "        stats = pd.Series(\n",
    "        {'model_number':model_number,\n",
    "            'model_type':'DecisionTreeClassifier',\n",
    "            'max_depth':max_depth,\n",
    "            'train_accuracy':accuracy_score(y_train, train['predicted']),\n",
    "            'validate_accuracy':accuracy_score(y_validate, validate['predicted']),\n",
    "            'test_accuracy':accuracy_score(y_test, test['predicted']),\n",
    "            'better_than_baseline':accuracy_score(y_validate, validate['predicted'])>validate_baseline,\n",
    "        })\n",
    "        # add to results df\n",
    "        results = pd.concat([results, stats], axis = 1)\n",
    "        model_number += 1\n",
    "\n",
    "    return results.T.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_number</th>\n",
       "      <th>model_type</th>\n",
       "      <th>solver</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>better_than_baseline</th>\n",
       "      <th>max_depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.418919</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.418919</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.581081</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.662162</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.72973</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.959459</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.37037</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.986486</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.37037</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_number              model_type solver train_accuracy  \\\n",
       "0     baseline                baseline    NaN       0.418919   \n",
       "1            1  DecisionTreeClassifier    NaN       0.418919   \n",
       "2            2  DecisionTreeClassifier    NaN       0.513514   \n",
       "3            3  DecisionTreeClassifier    NaN       0.581081   \n",
       "4            4  DecisionTreeClassifier    NaN       0.662162   \n",
       "5            5  DecisionTreeClassifier    NaN        0.72973   \n",
       "6            6  DecisionTreeClassifier    NaN       0.959459   \n",
       "7            7  DecisionTreeClassifier    NaN       0.986486   \n",
       "\n",
       "  validate_accuracy test_accuracy better_than_baseline max_depth  \n",
       "0          0.424242      0.407407                False       NaN  \n",
       "1          0.424242      0.407407                False         1  \n",
       "2          0.454545      0.333333                 True         2  \n",
       "3          0.393939      0.333333                False         3  \n",
       "4          0.424242      0.333333                False         4  \n",
       "5          0.454545      0.333333                 True         5  \n",
       "6          0.424242       0.37037                False        10  \n",
       "7          0.424242       0.37037                False       100  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_models3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models4():\n",
    "    \"\"\"\n",
    "    Run models with decision tree classifier\n",
    "    \"\"\"\n",
    "    #get raw data\n",
    "    df = pd.read_json('data.json')\n",
    "    df = prepare.prep_data(df)\n",
    "    # make vectorizer\n",
    "    tfidf = TfidfVectorizer()\n",
    "    # fit the vectorizer to the data and make df\n",
    "    X = tfidf.fit_transform(df['more_clean'])\n",
    "    y = df['language']\n",
    "\n",
    "    # split data into train and test\n",
    "    X_train, X_validate, X_test, y_train, y_validate, y_test = prepare.split_data_xy(X, y)\n",
    "    train = pd.DataFrame(dict(actual=y_train))\n",
    "    validate = pd.DataFrame(dict(actual=y_validate))\n",
    "    test = pd.DataFrame(dict(actual=y_test))\n",
    "    #get mode to use as baseline\n",
    "    mode = df.language.mode().values[0]\n",
    "    #get baseline_accuracy\n",
    "    train_baseline = baseline_accuracy(train, mode)\n",
    "    validate_baseline = baseline_accuracy(validate, mode)\n",
    "    test_baseline = baseline_accuracy(test, mode)\n",
    "    # make a df for results\n",
    "    results = pd.DataFrame()\n",
    "    # make baseline model\n",
    "    baseline_model = pd.Series({'model_number':'baseline','model_type':'baseline','train_accuracy':train_baseline,'validate_accuracy':validate_baseline,'test_accuracy':test_baseline, 'better_than_baseline':False})\n",
    "    # add baseline model to results df\n",
    "    results = pd.concat([results, baseline_model],axis = 0)\n",
    "    # make more models varying solver\n",
    "    model_number = results.shape[1]\n",
    "    max_depths = [1, 2, 3, 4, 5, 10, 100]\n",
    "    min_sample_leafs = [1, 2, 3, 4, 5, 10, 100]\n",
    "    criterion = ['gini', 'entropy']\n",
    "    for max_depth in max_depths:\n",
    "        for min_samples_leaf in min_sample_leafs:\n",
    "            for crit in criterion: \n",
    "                #make the model\n",
    "                rf = RandomForestClassifier(max_depth=max_depth, min_samples_leaf=min_samples_leaf, random_state=42, criterion=crit).fit(X_train, y_train)\n",
    "                # run model on data splits\n",
    "                train['predicted'] = rf.predict(X_train)\n",
    "                validate['predicted'] = rf.predict(X_validate)\n",
    "                test['predicted'] = rf.predict(X_test)\n",
    "                # make results series to add to results df\n",
    "                stats = pd.Series(\n",
    "                {'model_number':model_number,\n",
    "                    'model_type':'RandomForest',\n",
    "                    'max_depth':max_depth,\n",
    "                    'min_samples_leaf':min_samples_leaf,\n",
    "                    'criterion':crit,\n",
    "                    'train_accuracy':accuracy_score(y_train, train['predicted']),\n",
    "                    'validate_accuracy':accuracy_score(y_validate, validate['predicted']),\n",
    "                    'test_accuracy':accuracy_score(y_test, test['predicted']),\n",
    "                    'better_than_baseline':accuracy_score(y_validate, validate['predicted'])>validate_baseline,\n",
    "                })\n",
    "                # add to results df\n",
    "                results = pd.concat([results, stats], axis = 1)\n",
    "                model_number += 1\n",
    "\n",
    "    return results.T.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_number</th>\n",
       "      <th>model_type</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>better_than_baseline</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>criterion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>0.418919</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.418919</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.418919</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.418919</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.418919</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.418919</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>entropy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_number    model_type train_accuracy validate_accuracy test_accuracy  \\\n",
       "0      baseline      baseline       0.418919          0.424242      0.407407   \n",
       "1             1  RandomForest       0.432432          0.424242      0.407407   \n",
       "2             2  RandomForest       0.432432          0.424242      0.407407   \n",
       "3             3  RandomForest       0.432432          0.424242      0.407407   \n",
       "4             4  RandomForest       0.432432          0.424242      0.407407   \n",
       "..          ...           ...            ...               ...           ...   \n",
       "94           94  RandomForest       0.418919          0.424242      0.407407   \n",
       "95           95  RandomForest       0.418919          0.424242      0.407407   \n",
       "96           96  RandomForest       0.418919          0.424242      0.407407   \n",
       "97           97  RandomForest       0.418919          0.424242      0.407407   \n",
       "98           98  RandomForest       0.418919          0.424242      0.407407   \n",
       "\n",
       "   better_than_baseline max_depth min_samples_leaf criterion  \n",
       "0                 False       NaN              NaN       NaN  \n",
       "1                 False         1                1      gini  \n",
       "2                 False         1                1   entropy  \n",
       "3                 False         1                2      gini  \n",
       "4                 False         1                2   entropy  \n",
       "..                  ...       ...              ...       ...  \n",
       "94                False       100                5   entropy  \n",
       "95                False       100               10      gini  \n",
       "96                False       100               10   entropy  \n",
       "97                False       100              100      gini  \n",
       "98                False       100              100   entropy  \n",
       "\n",
       "[99 rows x 9 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = run_models4()#.sort_values(['validate_accuracy','test_accuracy'], ascending=False).head(3)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Jupyter Notebook    48\n",
       "R                   31\n",
       "HTML                22\n",
       "Python              19\n",
       "JavaScript          16\n",
       "Stata                5\n",
       "Java                 3\n",
       "Dart                 3\n",
       "Scala                2\n",
       "Swift                2\n",
       "MATLAB               1\n",
       "Shell                1\n",
       "TypeScript           1\n",
       "Ruby                 1\n",
       "Objective-C          1\n",
       "Scheme               1\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('data.json')\n",
    "df.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Python    56\n",
       "Other     32\n",
       "R         26\n",
       "HTML      20\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = prepare.prep_data(df)\n",
    "df.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>original</th>\n",
       "      <th>more_clean</th>\n",
       "      <th>unique_words</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>most_common_word</th>\n",
       "      <th>2nd_most_common_word</th>\n",
       "      <th>3rd_most_common_word</th>\n",
       "      <th>4th_most_common_word</th>\n",
       "      <th>5th_most_common_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mcastrolab/Brazil-Covid19-e0-change</td>\n",
       "      <td>R</td>\n",
       "      <td># Reduction in life expectancy in Brazil after...</td>\n",
       "      <td>reduction life expectancy brazil covid provide...</td>\n",
       "      <td>seen reduced al based first code publication i...</td>\n",
       "      <td>2949</td>\n",
       "      <td>352</td>\n",
       "      <td>211</td>\n",
       "      <td>life</td>\n",
       "      <td>expectancy</td>\n",
       "      <td>covid</td>\n",
       "      <td>state</td>\n",
       "      <td>data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jschoeley/de0anim</td>\n",
       "      <td>R</td>\n",
       "      <td># Animated annual changes in life-expectancy\\n...</td>\n",
       "      <td>animated annual change lifeexpectancy illustra...</td>\n",
       "      <td>losseshttpsgithubcomoxforddemsciex lifeexpecta...</td>\n",
       "      <td>166</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>animated</td>\n",
       "      <td>annual</td>\n",
       "      <td>change</td>\n",
       "      <td>lifeexpectancy</td>\n",
       "      <td>illustration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sychi77/Thoracic_Surgery_Patient_Survival</td>\n",
       "      <td>Python</td>\n",
       "      <td># Thoracic Surgery for Lung Cancer Data Set\\n ...</td>\n",
       "      <td>thoracic surgery lung cancer data set uci mach...</td>\n",
       "      <td>code first institute tnm one lung registry siz...</td>\n",
       "      <td>2058</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>surgery</td>\n",
       "      <td>f</td>\n",
       "      <td>data</td>\n",
       "      <td>lung</td>\n",
       "      <td>thoracic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ashtad63/HackerRank-Data-Scientist-Hiring-Test</td>\n",
       "      <td>Python</td>\n",
       "      <td># HackerRank Data Scientist Hiring Test: Predi...</td>\n",
       "      <td>hackerrank data scientist hiring test predict ...</td>\n",
       "      <td>first institute prediction united test organiz...</td>\n",
       "      <td>1011</td>\n",
       "      <td>135</td>\n",
       "      <td>86</td>\n",
       "      <td>country</td>\n",
       "      <td>life</td>\n",
       "      <td>expectancy</td>\n",
       "      <td>must</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OxfordDemSci/ex2020</td>\n",
       "      <td>R</td>\n",
       "      <td>&lt;p align=\"center\"&gt;\\n  &lt;img src=\"https://github...</td>\n",
       "      <td>p aligncenter img srchttpsgithubcomoxforddemsc...</td>\n",
       "      <td>functionality code ie sequential issue underta...</td>\n",
       "      <td>2259</td>\n",
       "      <td>234</td>\n",
       "      <td>172</td>\n",
       "      <td>data</td>\n",
       "      <td>relates</td>\n",
       "      <td>code</td>\n",
       "      <td>p</td>\n",
       "      <td>generic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>NalinKamboj/World-Data-Statistics</td>\n",
       "      <td>Other</td>\n",
       "      <td># WorldDataStatistics\\nFinal Assignment for Da...</td>\n",
       "      <td>worlddatastatistics final assignment data visu...</td>\n",
       "      <td>data visualization result httpsnalinkambojgith...</td>\n",
       "      <td>110</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>worlddatastatistics</td>\n",
       "      <td>final</td>\n",
       "      <td>assignment</td>\n",
       "      <td>data</td>\n",
       "      <td>visualization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>dashamet/Gapminder</td>\n",
       "      <td>HTML</td>\n",
       "      <td># GDP Per Capita vs. Life Expectancy \\n\\n* `ga...</td>\n",
       "      <td>gdp per caput v life expectancy gapminderrmd c...</td>\n",
       "      <td>code animated point continent data gdp represe...</td>\n",
       "      <td>256</td>\n",
       "      <td>37</td>\n",
       "      <td>28</td>\n",
       "      <td>continent</td>\n",
       "      <td>gdp</td>\n",
       "      <td>per</td>\n",
       "      <td>caput</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>ckraft-bot/GDHappiness</td>\n",
       "      <td>Python</td>\n",
       "      <td># GDHappiness\\nLooking at the 2021 data which ...</td>\n",
       "      <td>gdhappiness looking data country happiest vari...</td>\n",
       "      <td>happiest variable data expectancy looking exam...</td>\n",
       "      <td>131</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>life</td>\n",
       "      <td>gdhappiness</td>\n",
       "      <td>looking</td>\n",
       "      <td>data</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>johnwhittenstudio/project-5</td>\n",
       "      <td>Other</td>\n",
       "      <td># Super Galactic Age Calculator\\n\\n## by _**Jo...</td>\n",
       "      <td>super galactic age calculator john whitten dec...</td>\n",
       "      <td>based functionality code wherein activity issu...</td>\n",
       "      <td>3253</td>\n",
       "      <td>436</td>\n",
       "      <td>231</td>\n",
       "      <td>year</td>\n",
       "      <td>age</td>\n",
       "      <td>project</td>\n",
       "      <td>user</td>\n",
       "      <td>life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>arthurtham/octopet</td>\n",
       "      <td>Other</td>\n",
       "      <td>![Octopet](https://media.giphy.com/media/1hoKk...</td>\n",
       "      <td>octopethttpsmediagiphycommediahokkbnsbxvyhispe...</td>\n",
       "      <td>code learned first issue google consumption re...</td>\n",
       "      <td>1835</td>\n",
       "      <td>248</td>\n",
       "      <td>182</td>\n",
       "      <td>octocat</td>\n",
       "      <td>app</td>\n",
       "      <td>android</td>\n",
       "      <td>unhealthy</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               repo language  \\\n",
       "0               mcastrolab/Brazil-Covid19-e0-change        R   \n",
       "1                                 jschoeley/de0anim        R   \n",
       "2         sychi77/Thoracic_Surgery_Patient_Survival   Python   \n",
       "3    ashtad63/HackerRank-Data-Scientist-Hiring-Test   Python   \n",
       "4                               OxfordDemSci/ex2020        R   \n",
       "..                                              ...      ...   \n",
       "160               NalinKamboj/World-Data-Statistics    Other   \n",
       "162                              dashamet/Gapminder     HTML   \n",
       "163                          ckraft-bot/GDHappiness   Python   \n",
       "164                     johnwhittenstudio/project-5    Other   \n",
       "165                              arthurtham/octopet    Other   \n",
       "\n",
       "                                              original  \\\n",
       "0    # Reduction in life expectancy in Brazil after...   \n",
       "1    # Animated annual changes in life-expectancy\\n...   \n",
       "2    # Thoracic Surgery for Lung Cancer Data Set\\n ...   \n",
       "3    # HackerRank Data Scientist Hiring Test: Predi...   \n",
       "4    <p align=\"center\">\\n  <img src=\"https://github...   \n",
       "..                                                 ...   \n",
       "160  # WorldDataStatistics\\nFinal Assignment for Da...   \n",
       "162  # GDP Per Capita vs. Life Expectancy \\n\\n* `ga...   \n",
       "163  # GDHappiness\\nLooking at the 2021 data which ...   \n",
       "164  # Super Galactic Age Calculator\\n\\n## by _**Jo...   \n",
       "165  ![Octopet](https://media.giphy.com/media/1hoKk...   \n",
       "\n",
       "                                            more_clean  \\\n",
       "0    reduction life expectancy brazil covid provide...   \n",
       "1    animated annual change lifeexpectancy illustra...   \n",
       "2    thoracic surgery lung cancer data set uci mach...   \n",
       "3    hackerrank data scientist hiring test predict ...   \n",
       "4    p aligncenter img srchttpsgithubcomoxforddemsc...   \n",
       "..                                                 ...   \n",
       "160  worlddatastatistics final assignment data visu...   \n",
       "162  gdp per caput v life expectancy gapminderrmd c...   \n",
       "163  gdhappiness looking data country happiest vari...   \n",
       "164  super galactic age calculator john whitten dec...   \n",
       "165  octopethttpsmediagiphycommediahokkbnsbxvyhispe...   \n",
       "\n",
       "                                          unique_words  char_count  \\\n",
       "0    seen reduced al based first code publication i...        2949   \n",
       "1    losseshttpsgithubcomoxforddemsciex lifeexpecta...         166   \n",
       "2    code first institute tnm one lung registry siz...        2058   \n",
       "3    first institute prediction united test organiz...        1011   \n",
       "4    functionality code ie sequential issue underta...        2259   \n",
       "..                                                 ...         ...   \n",
       "160  data visualization result httpsnalinkambojgith...         110   \n",
       "162  code animated point continent data gdp represe...         256   \n",
       "163  happiest variable data expectancy looking exam...         131   \n",
       "164  based functionality code wherein activity issu...        3253   \n",
       "165  code learned first issue google consumption re...        1835   \n",
       "\n",
       "     word_count  unique_word_count     most_common_word 2nd_most_common_word  \\\n",
       "0           352                211                 life           expectancy   \n",
       "1            16                 16             animated               annual   \n",
       "2           234                150              surgery                    f   \n",
       "3           135                 86              country                 life   \n",
       "4           234                172                 data              relates   \n",
       "..          ...                ...                  ...                  ...   \n",
       "160           8                  8  worlddatastatistics                final   \n",
       "162          37                 28            continent                  gdp   \n",
       "163          16                 15                 life          gdhappiness   \n",
       "164         436                231                 year                  age   \n",
       "165         248                182              octocat                  app   \n",
       "\n",
       "    3rd_most_common_word 4th_most_common_word 5th_most_common_word  \n",
       "0                  covid                state                 data  \n",
       "1                 change       lifeexpectancy         illustration  \n",
       "2                   data                 lung             thoracic  \n",
       "3             expectancy                 must                 test  \n",
       "4                   code                    p              generic  \n",
       "..                   ...                  ...                  ...  \n",
       "160           assignment                 data        visualization  \n",
       "162                  per                caput                    v  \n",
       "163              looking                 data              country  \n",
       "164              project                 user                 life  \n",
       "165              android            unhealthy              healthy  \n",
       "\n",
       "[134 rows x 13 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>original</th>\n",
       "      <th>more_clean</th>\n",
       "      <th>unique_words</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>most_common_word</th>\n",
       "      <th>2nd_most_common_word</th>\n",
       "      <th>3rd_most_common_word</th>\n",
       "      <th>4th_most_common_word</th>\n",
       "      <th>5th_most_common_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mcastrolab/Brazil-Covid19-e0-change</td>\n",
       "      <td>R</td>\n",
       "      <td># Reduction in life expectancy in Brazil after...</td>\n",
       "      <td>reduction life expectancy brazil covid provide...</td>\n",
       "      <td>seen reduced al based first code publication i...</td>\n",
       "      <td>2949</td>\n",
       "      <td>352</td>\n",
       "      <td>211</td>\n",
       "      <td>life</td>\n",
       "      <td>expectancy</td>\n",
       "      <td>covid</td>\n",
       "      <td>state</td>\n",
       "      <td>data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jschoeley/de0anim</td>\n",
       "      <td>R</td>\n",
       "      <td># Animated annual changes in life-expectancy\\n...</td>\n",
       "      <td>animated annual change lifeexpectancy illustra...</td>\n",
       "      <td>losseshttpsgithubcomoxforddemsciex lifeexpecta...</td>\n",
       "      <td>166</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>animated</td>\n",
       "      <td>annual</td>\n",
       "      <td>change</td>\n",
       "      <td>lifeexpectancy</td>\n",
       "      <td>illustration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sychi77/Thoracic_Surgery_Patient_Survival</td>\n",
       "      <td>Python</td>\n",
       "      <td># Thoracic Surgery for Lung Cancer Data Set\\n ...</td>\n",
       "      <td>thoracic surgery lung cancer data set uci mach...</td>\n",
       "      <td>code first institute tnm one lung registry siz...</td>\n",
       "      <td>2058</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>surgery</td>\n",
       "      <td>f</td>\n",
       "      <td>data</td>\n",
       "      <td>lung</td>\n",
       "      <td>thoracic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ashtad63/HackerRank-Data-Scientist-Hiring-Test</td>\n",
       "      <td>Python</td>\n",
       "      <td># HackerRank Data Scientist Hiring Test: Predi...</td>\n",
       "      <td>hackerrank data scientist hiring test predict ...</td>\n",
       "      <td>first institute prediction united test organiz...</td>\n",
       "      <td>1011</td>\n",
       "      <td>135</td>\n",
       "      <td>86</td>\n",
       "      <td>country</td>\n",
       "      <td>life</td>\n",
       "      <td>expectancy</td>\n",
       "      <td>must</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OxfordDemSci/ex2020</td>\n",
       "      <td>R</td>\n",
       "      <td>&lt;p align=\"center\"&gt;\\n  &lt;img src=\"https://github...</td>\n",
       "      <td>p aligncenter img srchttpsgithubcomoxforddemsc...</td>\n",
       "      <td>functionality code ie sequential issue underta...</td>\n",
       "      <td>2259</td>\n",
       "      <td>234</td>\n",
       "      <td>172</td>\n",
       "      <td>data</td>\n",
       "      <td>relates</td>\n",
       "      <td>code</td>\n",
       "      <td>p</td>\n",
       "      <td>generic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             repo language  \\\n",
       "0             mcastrolab/Brazil-Covid19-e0-change        R   \n",
       "1                               jschoeley/de0anim        R   \n",
       "2       sychi77/Thoracic_Surgery_Patient_Survival   Python   \n",
       "3  ashtad63/HackerRank-Data-Scientist-Hiring-Test   Python   \n",
       "4                             OxfordDemSci/ex2020        R   \n",
       "\n",
       "                                            original  \\\n",
       "0  # Reduction in life expectancy in Brazil after...   \n",
       "1  # Animated annual changes in life-expectancy\\n...   \n",
       "2  # Thoracic Surgery for Lung Cancer Data Set\\n ...   \n",
       "3  # HackerRank Data Scientist Hiring Test: Predi...   \n",
       "4  <p align=\"center\">\\n  <img src=\"https://github...   \n",
       "\n",
       "                                          more_clean  \\\n",
       "0  reduction life expectancy brazil covid provide...   \n",
       "1  animated annual change lifeexpectancy illustra...   \n",
       "2  thoracic surgery lung cancer data set uci mach...   \n",
       "3  hackerrank data scientist hiring test predict ...   \n",
       "4  p aligncenter img srchttpsgithubcomoxforddemsc...   \n",
       "\n",
       "                                        unique_words  char_count  word_count  \\\n",
       "0  seen reduced al based first code publication i...        2949         352   \n",
       "1  losseshttpsgithubcomoxforddemsciex lifeexpecta...         166          16   \n",
       "2  code first institute tnm one lung registry siz...        2058         234   \n",
       "3  first institute prediction united test organiz...        1011         135   \n",
       "4  functionality code ie sequential issue underta...        2259         234   \n",
       "\n",
       "   unique_word_count most_common_word 2nd_most_common_word  \\\n",
       "0                211             life           expectancy   \n",
       "1                 16         animated               annual   \n",
       "2                150          surgery                    f   \n",
       "3                 86          country                 life   \n",
       "4                172             data              relates   \n",
       "\n",
       "  3rd_most_common_word 4th_most_common_word 5th_most_common_word  \n",
       "0                covid                state                 data  \n",
       "1               change       lifeexpectancy         illustration  \n",
       "2                 data                 lung             thoracic  \n",
       "3           expectancy                 must                 test  \n",
       "4                 code                    p              generic  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_unique_words(text):\n",
    "    \"\"\"\n",
    "    Get unique words in dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    words = text.split()\n",
    "    unique_words = set(words)\n",
    "    new_string = ' '.join(unique_words)\n",
    "    return new_string\n",
    "\n",
    "df['unique_words'] = df['more_clean'].apply(get_unique_words)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_unique_words(text, threshold=5):\n",
    "    \"\"\"\n",
    "    Get common unique words in dataframe, aka words that occur in multiple readme's\n",
    "    a word must appear in at least threshold readmes to be considered a common word\n",
    "    \"\"\"\n",
    "\n",
    "    words = text.split()\n",
    "    counter = Counter(words)\n",
    "    common_unique_words = [word for word, count in counter.items() if count >= threshold]\n",
    "    new_string = ' '.join(common_unique_words)\n",
    "    return new_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>all_words</th>\n",
       "      <th>unique_words</th>\n",
       "      <th>common_unique_words</th>\n",
       "      <th>n_words</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>mean_word_count</th>\n",
       "      <th>median_word_count</th>\n",
       "      <th>most_common_word</th>\n",
       "      <th>2nd_most_common_word</th>\n",
       "      <th>3rd_most_common_word</th>\n",
       "      <th>4th_most_common_word</th>\n",
       "      <th>5th_most_common_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HTML</td>\n",
       "      <td>output githubdocument readmemd generated readm...</td>\n",
       "      <td>reduced upscaled version outwidth see assessin...</td>\n",
       "      <td>using life data country expectancy file projec...</td>\n",
       "      <td>1221</td>\n",
       "      <td>612</td>\n",
       "      <td>61.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>life</td>\n",
       "      <td>expectancy</td>\n",
       "      <td>data</td>\n",
       "      <td>project</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Other</td>\n",
       "      <td>lifeexpectancy build statushttpstravisciorghem...</td>\n",
       "      <td>principe code lifeexpectancy rank key npm type...</td>\n",
       "      <td>code npm type data input year name install lif...</td>\n",
       "      <td>4126</td>\n",
       "      <td>1547</td>\n",
       "      <td>128.9</td>\n",
       "      <td>40.0</td>\n",
       "      <td>life</td>\n",
       "      <td>expectancy</td>\n",
       "      <td>project</td>\n",
       "      <td>data</td>\n",
       "      <td>using</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Python</td>\n",
       "      <td>thoracic surgery lung cancer data set uci mach...</td>\n",
       "      <td>code first institute tnm one lung registry siz...</td>\n",
       "      <td>code first one repository multiple related not...</td>\n",
       "      <td>8212</td>\n",
       "      <td>2273</td>\n",
       "      <td>146.6</td>\n",
       "      <td>71.0</td>\n",
       "      <td>life</td>\n",
       "      <td>expectancy</td>\n",
       "      <td>data</td>\n",
       "      <td>project</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R</td>\n",
       "      <td>reduction life expectancy brazil covid provide...</td>\n",
       "      <td>seen reduced al based first code publication i...</td>\n",
       "      <td>first code issue see population life per morta...</td>\n",
       "      <td>5467</td>\n",
       "      <td>1748</td>\n",
       "      <td>210.3</td>\n",
       "      <td>80.5</td>\n",
       "      <td>life</td>\n",
       "      <td>expectancy</td>\n",
       "      <td>data</td>\n",
       "      <td>r</td>\n",
       "      <td>year</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                                          all_words  \\\n",
       "0     HTML  output githubdocument readmemd generated readm...   \n",
       "1    Other  lifeexpectancy build statushttpstravisciorghem...   \n",
       "2   Python  thoracic surgery lung cancer data set uci mach...   \n",
       "3        R  reduction life expectancy brazil covid provide...   \n",
       "\n",
       "                                        unique_words  \\\n",
       "0  reduced upscaled version outwidth see assessin...   \n",
       "1  principe code lifeexpectancy rank key npm type...   \n",
       "2  code first institute tnm one lung registry siz...   \n",
       "3  seen reduced al based first code publication i...   \n",
       "\n",
       "                                 common_unique_words  n_words  \\\n",
       "0  using life data country expectancy file projec...     1221   \n",
       "1  code npm type data input year name install lif...     4126   \n",
       "2  code first one repository multiple related not...     8212   \n",
       "3  first code issue see population life per morta...     5467   \n",
       "\n",
       "   unique_word_count  mean_word_count  median_word_count most_common_word  \\\n",
       "0                612             61.0               33.0             life   \n",
       "1               1547            128.9               40.0             life   \n",
       "2               2273            146.6               71.0             life   \n",
       "3               1748            210.3               80.5             life   \n",
       "\n",
       "  2nd_most_common_word 3rd_most_common_word 4th_most_common_word  \\\n",
       "0           expectancy                 data              project   \n",
       "1           expectancy              project                 data   \n",
       "2           expectancy                 data              project   \n",
       "3           expectancy                 data                    r   \n",
       "\n",
       "  5th_most_common_word  \n",
       "0              country  \n",
       "1                using  \n",
       "2              country  \n",
       "3                 year  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine all strings in more_clean where language is the same\n",
    "languages = df.groupby('language')['more_clean'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "languages.rename(columns={'more_clean':'all_words'}, inplace=True)\n",
    "languages['unique_words'] = df.groupby('language')['unique_words'].apply(lambda x: ' '.join(x)).values\n",
    "languages['common_unique_words'] = languages.unique_words.apply(get_common_unique_words)\n",
    "languages['n_words'] = languages['all_words'].apply(lambda x: len(x.split()))\n",
    "languages['unique_word_count'] = languages['all_words'].apply(lambda x: len(set(x.split())))\n",
    "languages['mean_word_count'] = df.groupby('language')['word_count'].mean().values.round(1)\n",
    "languages['median_word_count'] = df.groupby('language')['word_count'].median().values.round(1)\n",
    "languages['most_common_word'] = languages['unique_words'].apply(lambda x: prepare.n_most_common_word(x))\n",
    "languages['2nd_most_common_word'] = languages['unique_words'].apply(lambda x: prepare.n_most_common_word(x,2))\n",
    "languages['3rd_most_common_word'] = languages['unique_words'].apply(lambda x: prepare.n_most_common_word(x,3))\n",
    "languages['4th_most_common_word'] = languages['unique_words'].apply(lambda x: prepare.n_most_common_word(x,4))\n",
    "languages['5th_most_common_word'] = languages['unique_words'].apply(lambda x: prepare.n_most_common_word(x,5))\n",
    "languages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_set = set(languages[languages.language=='HTML'].common_unique_words.values[0].split())\n",
    "python_set = set(languages[languages.language=='Python'].common_unique_words.values[0].split())\n",
    "r_set = set(languages[languages.language=='R'].common_unique_words.values[0].split())\n",
    "other_set = set(languages[languages.language=='Other'].common_unique_words.values[0].split())\n",
    "unique_to_html = html_set - python_set - r_set - other_set\n",
    "unique_to_python = python_set - html_set - r_set - other_set\n",
    "unique_to_r = r_set - html_set - python_set - other_set\n",
    "unique_to_other = other_set - html_set - python_set - r_set\n",
    "unique_to_lang = [unique_to_html, unique_to_python, unique_to_r, unique_to_other]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unique to lang is performed on full df but will be done on train then used for model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>all_words</th>\n",
       "      <th>unique_words</th>\n",
       "      <th>common_unique_words</th>\n",
       "      <th>n_words</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>mean_word_count</th>\n",
       "      <th>median_word_count</th>\n",
       "      <th>most_common_word</th>\n",
       "      <th>2nd_most_common_word</th>\n",
       "      <th>3rd_most_common_word</th>\n",
       "      <th>4th_most_common_word</th>\n",
       "      <th>5th_most_common_word</th>\n",
       "      <th>unique_to_language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HTML</td>\n",
       "      <td>output githubdocument readmemd generated readm...</td>\n",
       "      <td>reduced upscaled version outwidth see assessin...</td>\n",
       "      <td>using life data country expectancy file projec...</td>\n",
       "      <td>1221</td>\n",
       "      <td>612</td>\n",
       "      <td>61.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>life</td>\n",
       "      <td>expectancy</td>\n",
       "      <td>data</td>\n",
       "      <td>project</td>\n",
       "      <td>country</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Other</td>\n",
       "      <td>lifeexpectancy build statushttpstravisciorghem...</td>\n",
       "      <td>principe code lifeexpectancy rank key npm type...</td>\n",
       "      <td>code npm type data input year name install lif...</td>\n",
       "      <td>4126</td>\n",
       "      <td>1547</td>\n",
       "      <td>128.9</td>\n",
       "      <td>40.0</td>\n",
       "      <td>life</td>\n",
       "      <td>expectancy</td>\n",
       "      <td>project</td>\n",
       "      <td>data</td>\n",
       "      <td>using</td>\n",
       "      <td>{based, prediction, developing, united, alcoho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Python</td>\n",
       "      <td>thoracic surgery lung cancer data set uci mach...</td>\n",
       "      <td>code first institute tnm one lung registry siz...</td>\n",
       "      <td>code first one repository multiple related not...</td>\n",
       "      <td>8212</td>\n",
       "      <td>2273</td>\n",
       "      <td>146.6</td>\n",
       "      <td>71.0</td>\n",
       "      <td>life</td>\n",
       "      <td>expectancy</td>\n",
       "      <td>data</td>\n",
       "      <td>project</td>\n",
       "      <td>country</td>\n",
       "      <td>{function, includes, description, issue, v, es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R</td>\n",
       "      <td>reduction life expectancy brazil covid provide...</td>\n",
       "      <td>seen reduced al based first code publication i...</td>\n",
       "      <td>first code issue see population life per morta...</td>\n",
       "      <td>5467</td>\n",
       "      <td>1748</td>\n",
       "      <td>210.3</td>\n",
       "      <td>80.5</td>\n",
       "      <td>life</td>\n",
       "      <td>expectancy</td>\n",
       "      <td>data</td>\n",
       "      <td>r</td>\n",
       "      <td>year</td>\n",
       "      <td>{point, npm, type, instruction, process, direc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                                          all_words  \\\n",
       "0     HTML  output githubdocument readmemd generated readm...   \n",
       "1    Other  lifeexpectancy build statushttpstravisciorghem...   \n",
       "2   Python  thoracic surgery lung cancer data set uci mach...   \n",
       "3        R  reduction life expectancy brazil covid provide...   \n",
       "\n",
       "                                        unique_words  \\\n",
       "0  reduced upscaled version outwidth see assessin...   \n",
       "1  principe code lifeexpectancy rank key npm type...   \n",
       "2  code first institute tnm one lung registry siz...   \n",
       "3  seen reduced al based first code publication i...   \n",
       "\n",
       "                                 common_unique_words  n_words  \\\n",
       "0  using life data country expectancy file projec...     1221   \n",
       "1  code npm type data input year name install lif...     4126   \n",
       "2  code first one repository multiple related not...     8212   \n",
       "3  first code issue see population life per morta...     5467   \n",
       "\n",
       "   unique_word_count  mean_word_count  median_word_count most_common_word  \\\n",
       "0                612             61.0               33.0             life   \n",
       "1               1547            128.9               40.0             life   \n",
       "2               2273            146.6               71.0             life   \n",
       "3               1748            210.3               80.5             life   \n",
       "\n",
       "  2nd_most_common_word 3rd_most_common_word 4th_most_common_word  \\\n",
       "0           expectancy                 data              project   \n",
       "1           expectancy              project                 data   \n",
       "2           expectancy                 data              project   \n",
       "3           expectancy                 data                    r   \n",
       "\n",
       "  5th_most_common_word                                 unique_to_language  \n",
       "0              country                                                 {}  \n",
       "1                using  {based, prediction, developing, united, alcoho...  \n",
       "2              country  {function, includes, description, issue, v, es...  \n",
       "3                 year  {point, npm, type, instruction, process, direc...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages['unique_to_language'] = unique_to_lang\n",
    "languages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>original</th>\n",
       "      <th>more_clean</th>\n",
       "      <th>unique_words</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>most_common_word</th>\n",
       "      <th>2nd_most_common_word</th>\n",
       "      <th>3rd_most_common_word</th>\n",
       "      <th>4th_most_common_word</th>\n",
       "      <th>5th_most_common_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mcastrolab/Brazil-Covid19-e0-change</td>\n",
       "      <td>R</td>\n",
       "      <td># Reduction in life expectancy in Brazil after...</td>\n",
       "      <td>reduction life expectancy brazil covid provide...</td>\n",
       "      <td>seen reduced al based first code publication i...</td>\n",
       "      <td>2949</td>\n",
       "      <td>352</td>\n",
       "      <td>211</td>\n",
       "      <td>life</td>\n",
       "      <td>expectancy</td>\n",
       "      <td>covid</td>\n",
       "      <td>state</td>\n",
       "      <td>data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jschoeley/de0anim</td>\n",
       "      <td>R</td>\n",
       "      <td># Animated annual changes in life-expectancy\\n...</td>\n",
       "      <td>animated annual change lifeexpectancy illustra...</td>\n",
       "      <td>losseshttpsgithubcomoxforddemsciex lifeexpecta...</td>\n",
       "      <td>166</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>animated</td>\n",
       "      <td>annual</td>\n",
       "      <td>change</td>\n",
       "      <td>lifeexpectancy</td>\n",
       "      <td>illustration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sychi77/Thoracic_Surgery_Patient_Survival</td>\n",
       "      <td>Python</td>\n",
       "      <td># Thoracic Surgery for Lung Cancer Data Set\\n ...</td>\n",
       "      <td>thoracic surgery lung cancer data set uci mach...</td>\n",
       "      <td>code first institute tnm one lung registry siz...</td>\n",
       "      <td>2058</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>surgery</td>\n",
       "      <td>f</td>\n",
       "      <td>data</td>\n",
       "      <td>lung</td>\n",
       "      <td>thoracic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ashtad63/HackerRank-Data-Scientist-Hiring-Test</td>\n",
       "      <td>Python</td>\n",
       "      <td># HackerRank Data Scientist Hiring Test: Predi...</td>\n",
       "      <td>hackerrank data scientist hiring test predict ...</td>\n",
       "      <td>first institute prediction united test organiz...</td>\n",
       "      <td>1011</td>\n",
       "      <td>135</td>\n",
       "      <td>86</td>\n",
       "      <td>country</td>\n",
       "      <td>life</td>\n",
       "      <td>expectancy</td>\n",
       "      <td>must</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OxfordDemSci/ex2020</td>\n",
       "      <td>R</td>\n",
       "      <td>&lt;p align=\"center\"&gt;\\n  &lt;img src=\"https://github...</td>\n",
       "      <td>p aligncenter img srchttpsgithubcomoxforddemsc...</td>\n",
       "      <td>functionality code ie sequential issue underta...</td>\n",
       "      <td>2259</td>\n",
       "      <td>234</td>\n",
       "      <td>172</td>\n",
       "      <td>data</td>\n",
       "      <td>relates</td>\n",
       "      <td>code</td>\n",
       "      <td>p</td>\n",
       "      <td>generic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             repo language  \\\n",
       "0             mcastrolab/Brazil-Covid19-e0-change        R   \n",
       "1                               jschoeley/de0anim        R   \n",
       "2       sychi77/Thoracic_Surgery_Patient_Survival   Python   \n",
       "3  ashtad63/HackerRank-Data-Scientist-Hiring-Test   Python   \n",
       "4                             OxfordDemSci/ex2020        R   \n",
       "\n",
       "                                            original  \\\n",
       "0  # Reduction in life expectancy in Brazil after...   \n",
       "1  # Animated annual changes in life-expectancy\\n...   \n",
       "2  # Thoracic Surgery for Lung Cancer Data Set\\n ...   \n",
       "3  # HackerRank Data Scientist Hiring Test: Predi...   \n",
       "4  <p align=\"center\">\\n  <img src=\"https://github...   \n",
       "\n",
       "                                          more_clean  \\\n",
       "0  reduction life expectancy brazil covid provide...   \n",
       "1  animated annual change lifeexpectancy illustra...   \n",
       "2  thoracic surgery lung cancer data set uci mach...   \n",
       "3  hackerrank data scientist hiring test predict ...   \n",
       "4  p aligncenter img srchttpsgithubcomoxforddemsc...   \n",
       "\n",
       "                                        unique_words  char_count  word_count  \\\n",
       "0  seen reduced al based first code publication i...        2949         352   \n",
       "1  losseshttpsgithubcomoxforddemsciex lifeexpecta...         166          16   \n",
       "2  code first institute tnm one lung registry siz...        2058         234   \n",
       "3  first institute prediction united test organiz...        1011         135   \n",
       "4  functionality code ie sequential issue underta...        2259         234   \n",
       "\n",
       "   unique_word_count most_common_word 2nd_most_common_word  \\\n",
       "0                211             life           expectancy   \n",
       "1                 16         animated               annual   \n",
       "2                150          surgery                    f   \n",
       "3                 86          country                 life   \n",
       "4                172             data              relates   \n",
       "\n",
       "  3rd_most_common_word 4th_most_common_word 5th_most_common_word  \n",
       "0                covid                state                 data  \n",
       "1               change       lifeexpectancy         illustration  \n",
       "2                 data                 lung             thoracic  \n",
       "3           expectancy                 must                 test  \n",
       "4                 code                    p              generic  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language\n",
       "HTML       61.0\n",
       "Other     128.9\n",
       "Python    146.6\n",
       "R         210.3\n",
       "Name: word_count, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# groupby by language and get the average word count\n",
    "df.groupby('language')['word_count'].mean().round(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141.98507462686567"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.word_count.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = df[df.language=='Python'].word_count\n",
    "sample.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = df[df.language=='R'].word_count\n",
    "sample.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.word_count==0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WilcoxonResult(statistic=769.0, pvalue=0.9933148172974534)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group1 = df[df.language=='Python'].word_count\n",
    "group2 = df.word_count.sample(len(group1))\n",
    "import scipy.stats as stats\n",
    "stats.wilcoxon(group1, group2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56,)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group2 = df.word_count.sample(len(group1))\n",
    "group2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56,)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: word_count, dtype: int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.language=='r'].word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
